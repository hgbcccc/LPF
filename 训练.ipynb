{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工业用地-单模型\n",
    "\n",
    "\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
    "    | Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
    "    | ExtraTreesRegressor                 | 0.9805             | 1.0013             | 2.8341             | 47.9948            | 6.9278             | 0.69               | 1.69               |\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据导入成功\n",
      "原始数据的前几行：\n",
      "       Y  pointID  距五金、机电、仪器仪表的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "0  392.0        0     8235.491989  ...        0.0      0.0        0.0\n",
      "1  392.0        1     8344.872005  ...        0.0      0.0        0.0\n",
      "2  392.0        2     8305.661573  ...        0.0      0.0        0.0\n",
      "3  392.0        3     8598.139455  ...        0.0      0.0        0.0\n",
      "4  395.0        4     9125.101321  ...        0.0      0.0        0.0\n",
      "\n",
      "[5 rows x 460 columns]\n",
      "数据导入成功\n",
      "标准化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度   木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                                \n",
      "0              3.104798   2.058450     3.549202  ...  -0.511798 -0.197218  -0.092288\n",
      "1              3.156968   2.062838     3.543530  ...  -0.511798 -0.197218  -0.092288\n",
      "2              3.138266   2.083815     3.502762  ...  -0.511798 -0.197218  -0.092288\n",
      "3              3.277766   2.058667     3.558979  ...  -0.511798 -0.197218  -0.092288\n",
      "4              3.529107   2.035347     3.624226  ...  -0.511798 -0.197218  -0.092288\n",
      "\n",
      "[5 rows x 458 columns]\n",
      "归一化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                               \n",
      "0              0.831400   0.866313     0.958450  ...        0.0      0.0        0.0\n",
      "1              0.842505   0.867589     0.957145  ...        0.0      0.0        0.0\n",
      "2              0.838524   0.873690     0.947764  ...        0.0      0.0        0.0\n",
      "3              0.868219   0.866377     0.960700  ...        0.0      0.0        0.0\n",
      "4              0.921721   0.859595     0.975714  ...        0.0      0.0        0.0\n",
      "\n",
      "[5 rows x 458 columns]\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.9805             | 1.0013             | 2.8341             | 47.9948            | 6.9278             | 0.69               | 1.69               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "模型评估结果已保存到 ./模型评估/建设用地/单模型/工业用地模型评估.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training.py --data_path \"特征工程处理csv/工业用地_修正_处理后.csv\" \\\n",
    "                        --model_save_path \"./model/建设用地/单模型/工业用地\" \\\n",
    "                        --comparison_save_path \"./模型评估/建设用地/单模型/工业用地模型评估.csv\" \\\n",
    "                        --target \"Y\" \\\n",
    "                        --model_list \"ExtraTreesRegressor\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 住宅-单模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
    "    | Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
    "    | ExtraTreesRegressor                 | 0.9915             | 1.0359             | 150.3464           | 58308.5794         | 241.4717           | 3.31               | 5.32               |\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据导入成功\n",
      "原始数据的前几行：\n",
      "       Y  pointID  距五金、机电、仪器仪表的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "0  520.0        0      459.199862  ...   0.000000      0.0        0.0\n",
      "1  599.0        1       84.560410  ...   2.561046      0.0        0.0\n",
      "2  710.0        2       39.305226  ...   3.226699      0.0        0.0\n",
      "3  750.0        3        8.758938  ...   3.226699      0.0        0.0\n",
      "4  607.0        4       70.498438  ...   3.480907      0.0        0.0\n",
      "\n",
      "[5 rows x 464 columns]\n",
      "数据导入成功\n",
      "标准化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度   木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                                \n",
      "0             -0.297488  -0.489096     1.870108  ...  -0.999914 -0.295288  -0.148376\n",
      "1             -0.384090  -0.540085     1.795598  ...  -0.956665 -0.295288  -0.148376\n",
      "2             -0.394552  -0.549593     1.783087  ...  -0.945424 -0.295288  -0.148376\n",
      "3             -0.401613  -0.549999     1.777950  ...  -0.945424 -0.295288  -0.148376\n",
      "4             -0.387341  -0.558177     1.748267  ...  -0.941131 -0.295288  -0.148376\n",
      "\n",
      "[5 rows x 462 columns]\n",
      "归一化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                               \n",
      "0              0.020121   0.021172     0.564920  ...   0.000000      0.0        0.0\n",
      "1              0.003573   0.007607     0.547245  ...   0.004941      0.0        0.0\n",
      "2              0.001574   0.005077     0.544277  ...   0.006225      0.0        0.0\n",
      "3              0.000224   0.004969     0.543058  ...   0.006225      0.0        0.0\n",
      "4              0.002952   0.002793     0.536017  ...   0.006716      0.0        0.0\n",
      "\n",
      "[5 rows x 462 columns]\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.9915             | 1.0359             | 150.3464           | 58308.5794         | 241.4717           | 3.31               | 5.32               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "模型评估结果已保存到 ./模型评估/建设用地/单模型/住宅用地模型评估.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training.py --data_path \"特征工程处理csv\\住宅用地_修正_处理后.csv\" \\\n",
    "                        --model_save_path \"./model/建设用地/单模型/住宅用地\" \\\n",
    "                        --comparison_save_path \"./模型评估/建设用地/单模型/住宅用地模型评估.csv\" \\\n",
    "                        --target \"Y\" \\\n",
    "                        --model_list \"ExtraTreesRegressor\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 商业-单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据导入成功\n",
      "原始数据的前几行：\n",
      "       Y  pointID  距五金、机电、仪器仪表的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "0  393.0        0      492.075663  ...   0.000000      0.0        0.0\n",
      "1  547.0        1      458.530541  ...   0.000000      0.0        0.0\n",
      "2  787.0        2      135.740575  ...   2.156290      0.0        0.0\n",
      "3  744.0        3       87.805493  ...   2.561046      0.0        0.0\n",
      "4  797.0        4       84.801155  ...   2.561046      0.0        0.0\n",
      "\n",
      "[5 rows x 464 columns]\n",
      "数据导入成功\n",
      "标准化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                               \n",
      "0             -0.322159  -0.548219     1.733652  ...  -0.886505 -0.30472  -0.139112\n",
      "1             -0.328957  -0.552503     1.727506  ...  -0.886505 -0.30472  -0.139112\n",
      "2             -0.394380  -0.593747     1.666761  ...  -0.855835 -0.30472  -0.139112\n",
      "3             -0.404096  -0.601938     1.658571  ...  -0.850078 -0.30472  -0.139112\n",
      "4             -0.404705  -0.600661     1.657396  ...  -0.850078 -0.30472  -0.139112\n",
      "\n",
      "[5 rows x 462 columns]\n",
      "归一化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                               \n",
      "0              0.021908   0.022270     0.566482  ...   0.000000      0.0        0.0\n",
      "1              0.020409   0.021069     0.564944  ...   0.000000      0.0        0.0\n",
      "2              0.005985   0.009505     0.549744  ...   0.003914      0.0        0.0\n",
      "3              0.003843   0.007208     0.547695  ...   0.004648      0.0        0.0\n",
      "4              0.003708   0.007566     0.547401  ...   0.004648      0.0        0.0\n",
      "\n",
      "[5 rows x 462 columns]\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.9204             | 0.8173             | 404.7282           | 510180.9515        | 714.2695           | 11.04              | 19.49              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "模型评估结果已保存到 ./模型评估/建设用地/单模型/商业用地模型评估.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training.py --data_path \"特征工程处理csv\\商业用地.csv\" \\\n",
    "                        --model_save_path \"./model/建设用地/单模型/商业用地\" \\\n",
    "                        --comparison_save_path \"./模型评估/建设用地/单模型/商业用地模型评估.csv\" \\\n",
    "                        --target \"Y\" \\\n",
    "                        --test_size 0.2 \\\n",
    "                        --random_state 45 \\\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 草地-单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据导入成功\n",
      "原始数据的前几行：\n",
      "        Y  pointID  距五金、机电、仪器仪表的距离  ...  RD-03-1-干线主干路核密度  住、宿POI核密度  木材加工核密度\n",
      "0  1.4555        0    11053.583959  ...           0.00000        0.0      0.0\n",
      "1  1.4486        1    23011.828454  ...           0.00000        0.0      0.0\n",
      "2  1.4418        2    22783.563372  ...           0.00000        0.0      0.0\n",
      "3  1.5920        3     2933.779442  ...           0.00000        0.0      0.0\n",
      "4  1.5920        4     2697.794933  ...           0.00038        0.0      0.0\n",
      "\n",
      "[5 rows x 453 columns]\n",
      "数据导入成功\n",
      "标准化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  ...  住、宿POI核密度   木材加工核密度\n",
      "pointID                             ...                     \n",
      "0              0.832533   0.091271  ...  -0.171653 -0.144933\n",
      "1              3.146349   1.750338  ...  -0.171653 -0.144933\n",
      "2              3.102182   1.718523  ...  -0.171653 -0.144933\n",
      "3             -0.738579   1.693046  ...  -0.171653 -0.144933\n",
      "4             -0.784240   1.655797  ...  -0.171653 -0.144933\n",
      "\n",
      "[5 rows x 451 columns]\n",
      "归一化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  ...  住、宿POI核密度  木材加工核密度\n",
      "pointID                             ...                    \n",
      "0              0.428898   0.338212  ...        0.0      0.0\n",
      "1              0.911225   0.739636  ...        0.0      0.0\n",
      "2              0.902018   0.731938  ...        0.0      0.0\n",
      "3              0.101392   0.725774  ...        0.0      0.0\n",
      "4              0.091874   0.716761  ...        0.0      0.0\n",
      "\n",
      "[5 rows x 451 columns]\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForestRegressor               | 0.7765             | 1.0109             | 0.1052             | 0.0172             | 0.1312             | 6.06               | 7.56               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.7660             | 1.0114             | 0.1074             | 0.0180             | 0.1343             | 6.19               | 7.74               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreeRegressor                  | 0.8056             | 1.0095             | 0.1031             | 0.0150             | 0.1224             | 5.94               | 7.05               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "模型评估结果已保存到 ./模型评估/农用地/单模型/草地模型评估.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training.py --data_path \"特征工程处理csv\\草地_修正_处理后.csv\" \\\n",
    "                        --model_save_path \"./model/农用地/单模型/草地\" \\\n",
    "                        --comparison_save_path \"./模型评估/农用地/单模型/草地模型评估.csv\" \\\n",
    "                        --target \"Y\" \\\n",
    "                        --test_size 0.2 \\\n",
    "                        --random_state 45 \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设施农用地-单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据导入成功\n",
      "原始数据的前几行：\n",
      "        Y  pointID  距五金、机电、仪器仪表的距离  ...  住、宿POI核密度   木材加工核密度  轨道S1号线核密度\n",
      "0  7.8887        0      374.742582  ...        0.0  65851.44        0.0\n",
      "1  8.6455        1      610.889748  ...        0.0  83686.63        0.0\n",
      "2  9.1961        2    11578.311104  ...        0.0   2100.76        0.0\n",
      "3  7.5303        3    11318.278637  ...        0.0      0.00        0.0\n",
      "4  6.3742        4     6211.984249  ...        0.0      0.00        0.0\n",
      "\n",
      "[5 rows x 458 columns]\n",
      "数据导入成功\n",
      "标准化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度   木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                                \n",
      "0             -1.076461  -0.574293    -0.643478  ...   -0.24498  6.013512  -0.190333\n",
      "1             -1.021544  -0.584198    -0.751327  ...   -0.24498  7.694946  -0.190333\n",
      "2              1.528933  -0.103979     1.235811  ...   -0.24498  0.003338  -0.190333\n",
      "3              1.468462  -0.049309     1.180874  ...   -0.24498 -0.194714  -0.190333\n",
      "4              0.280992  -0.510821     0.079651  ...   -0.24498 -0.194714  -0.190333\n",
      "\n",
      "[5 rows x 456 columns]\n",
      "归一化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度   木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                                \n",
      "0              0.013361   0.125718     0.141027  ...        0.0  0.786881        0.0\n",
      "1              0.025893   0.123091     0.110807  ...        0.0  1.000000        0.0\n",
      "2              0.607896   0.250454     0.667617  ...        0.0  0.025103        0.0\n",
      "3              0.594097   0.264954     0.652223  ...        0.0  0.000000        0.0\n",
      "4              0.323124   0.142552     0.343653  ...        0.0  0.000000        0.0\n",
      "\n",
      "[5 rows x 456 columns]\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LinearRegression                    | 0.5734             | 1.0206             | 0.5170             | 0.4858             | 0.6970             | 7.53               | 10.15              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Ridge                               | 0.6964             | 1.0147             | 0.4369             | 0.3457             | 0.5880             | 6.36               | 8.56               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Lasso                               | -0.0675            | 1.0515             | 0.8675             | 1.2157             | 1.1026             | 12.63              | 16.05              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ElasticNet                          | -0.0675            | 1.0515             | 0.8675             | 1.2157             | 1.1026             | 12.63              | 16.05              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| BayesianRidge                       | 0.6962             | 1.0147             | 0.4373             | 0.3460             | 0.5882             | 6.37               | 8.56               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LassoLars                           | -0.0675            | 1.0515             | 0.8675             | 1.2157             | 1.1026             | 12.63              | 16.05              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| PassiveAggressiveRegressor          | 0.5377             | 1.0223             | 0.5383             | 0.5265             | 0.7256             | 7.84               | 10.56              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| TheilSenRegressor                   | 0.5212             | 1.0231             | 0.4920             | 0.5452             | 0.7384             | 7.16               | 10.75              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HuberRegressor                      | 0.6301             | 1.0179             | 0.4529             | 0.4212             | 0.6490             | 6.59               | 9.45               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| OrthogonalMatchingPursuit           | 0.6474             | 1.0170             | 0.4626             | 0.4016             | 0.6337             | 6.73               | 9.22               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| TweedieRegressor                    | 0.4273             | 1.0276             | 0.5472             | 0.6522             | 0.8076             | 7.97               | 11.76              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| PoissonRegressor                    | 0.5829             | 1.0201             | 0.4992             | 0.4750             | 0.6892             | 7.27               | 10.03              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GammaRegressor                      | 0.4258             | 1.0277             | 0.5423             | 0.6540             | 0.8087             | 7.89               | 11.77              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForestRegressor               | 0.5436             | 1.0220             | 0.5152             | 0.5198             | 0.7210             | 7.50               | 10.50              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.6634             | 1.0162             | 0.4619             | 0.3833             | 0.6191             | 6.72               | 9.01               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoostingRegressor           | 0.4897             | 1.0246             | 0.5432             | 0.5811             | 0.7623             | 7.91               | 11.10              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBRegressor                        | 0.4847             | 1.0249             | 0.5121             | 0.5869             | 0.7661             | 7.45               | 11.15              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12332\n",
      "[LightGBM] [Info] Number of data points in the train set: 85, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 6.592557\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| lgb.LGBMRegressor                   | 0.5319             | 1.0226             | 0.5369             | 0.5331             | 0.7301             | 7.82               | 10.63              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoostRegressor                   | 0.5752             | 1.0205             | 0.5534             | 0.4838             | 0.6955             | 8.06               | 10.12              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.5433             | 1.0220             | 0.5445             | 0.5201             | 0.7212             | 7.93               | 10.50              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LinearSVR                           | 0.6284             | 1.0179             | 0.4297             | 0.4231             | 0.6505             | 6.25               | 9.47               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR                                 | 0.5450             | 1.0220             | 0.4745             | 0.5181             | 0.7198             | 6.91               | 10.48              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| NuSVR                               | 0.5457             | 1.0219             | 0.4738             | 0.5173             | 0.7193             | 6.90               | 10.47              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| DecisionTreeRegressor               | 0.4511             | 1.0265             | 0.5825             | 0.6251             | 0.7906             | 8.48               | 11.51              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreeRegressor                  | 0.6767             | 1.0156             | 0.4270             | 0.3682             | 0.6068             | 6.22               | 8.83               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| KNeighborsRegressor                 | 0.3545             | 1.0312             | 0.5888             | 0.7351             | 0.8574             | 8.57               | 12.48              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GaussianProcessRegressor            | -20.1048           | 2.0189             | 4.6797             | 24.0353            | 4.9026             | 68.12              | 71.36              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "模型评估结果已保存到 ./模型评估/农用地/单模型/设施农用地模型评估.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training.py --data_path \"特征工程处理csv\\设施农用地_修正_处理后.csv\" \\\n",
    "                        --model_save_path \"./model/农用地/单模型/设施农用地\" \\\n",
    "                        --comparison_save_path \"./模型评估/农用地/单模型/设施农用地模型评估.csv\" \\\n",
    "                        --target \"Y\" \\\n",
    "                        --test_size 0.2 \\\n",
    "                        --random_state 45 \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 坑塘水面-单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据导入成功\n",
      "原始数据的前几行：\n",
      "        Y  pointID  距五金、机电、仪器仪表的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "0  7.2050        0     3503.849873  ...        0.0      0.0        0.0\n",
      "1  7.7991        1     3146.814401  ...        0.0      0.0        0.0\n",
      "2  7.5215        2     2537.077492  ...        0.0      0.0        0.0\n",
      "3  6.4338        3     2812.596438  ...        0.0      0.0        0.0\n",
      "4  6.3549        4     2197.351990  ...        0.0      0.0        0.0\n",
      "\n",
      "[5 rows x 459 columns]\n",
      "数据导入成功\n",
      "标准化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度   木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                                \n",
      "0             -0.684227   1.211443    -0.516541  ...  -0.203868 -0.187818  -0.061663\n",
      "1             -0.763485   1.231074    -0.592607  ...  -0.203868 -0.187818  -0.061663\n",
      "2             -0.898839   1.104204    -0.718629  ...  -0.203868 -0.187818  -0.061663\n",
      "3             -0.837677   1.196841    -0.698601  ...  -0.203868 -0.187818  -0.061663\n",
      "4             -0.974254   1.121992    -0.835557  ...  -0.203868 -0.187818  -0.061663\n",
      "\n",
      "[5 rows x 457 columns]\n",
      "归一化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                               \n",
      "0              0.148008   0.755411     0.244801  ...        0.0      0.0        0.0\n",
      "1              0.131566   0.761096     0.224372  ...        0.0      0.0        0.0\n",
      "2              0.103485   0.724354     0.190525  ...        0.0      0.0        0.0\n",
      "3              0.116174   0.751182     0.195904  ...        0.0      0.0        0.0\n",
      "4              0.087840   0.729505     0.159121  ...        0.0      0.0        0.0\n",
      "\n",
      "[5 rows x 457 columns]\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR                                 | 0.7430             | 1.0330             | 0.2559             | 0.1344             | 0.3666             | 4.15               | 5.94               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| NuSVR                               | 0.7425             | 1.0331             | 0.2577             | 0.1347             | 0.3670             | 4.18               | 5.95               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| DecisionTreeRegressor               | 0.4972             | 1.0646             | 0.3661             | 0.2630             | 0.5128             | 5.93               | 8.31               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreeRegressor                  | 0.4903             | 1.0654             | 0.3572             | 0.2666             | 0.5164             | 5.79               | 8.37               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| KNeighborsRegressor                 | 0.6699             | 1.0424             | 0.3021             | 0.1727             | 0.4155             | 4.89               | 6.73               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GaussianProcessRegressor            | -17.6318           | 3.3922             | 2.5838             | 9.7458             | 3.1218             | 41.86              | 50.58              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "模型评估结果已保存到 ./模型评估/农用地/单模型/坑塘水面模型评估.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training.py --data_path \"特征工程处理csv\\坑塘水面_修正_处理后.csv\" \\\n",
    "                        --model_save_path \"./model/农用地/单模型/坑塘水面\" \\\n",
    "                        --comparison_save_path \"./模型评估/农用地/单模型/坑塘水面模型评估.csv\" \\\n",
    "                        --target \"Y\" \\\n",
    "                        --test_size 0.2 \\\n",
    "                        --random_state 45 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 公服用地-单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据导入成功\n",
      "原始数据的前几行：\n",
      "       Y  pointID  距五金、机电、仪器仪表的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "0  476.0        0      131.137037  ...   1.758742      0.0        0.0\n",
      "1  390.0        1      165.378520  ...   1.334468      0.0        0.0\n",
      "2  485.0        2       90.598550  ...   2.561046      0.0        0.0\n",
      "3  535.0        3       40.776196  ...   3.817029      0.0        0.0\n",
      "4  537.0        4       91.158275  ...   3.058959      0.0        0.0\n",
      "\n",
      "[5 rows x 464 columns]\n",
      "数据导入成功\n",
      "标准化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度   木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                                \n",
      "0             -0.499281  -0.601906     1.480723  ...  -0.552894 -0.161565  -0.251635\n",
      "1             -0.492840  -0.596590     1.484349  ...  -0.561960 -0.161565  -0.251635\n",
      "2             -0.506907  -0.608664     1.472116  ...  -0.535750 -0.161565  -0.251635\n",
      "3             -0.516279  -0.628716     1.427665  ...  -0.508911 -0.161565  -0.251635\n",
      "4             -0.506801  -0.616645     1.414253  ...  -0.525110 -0.161565  -0.251635\n",
      "\n",
      "[5 rows x 462 columns]\n",
      "归一化后的特征数据的前几行：\n",
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度  木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                               \n",
      "0              0.005556   0.008097     0.559641  ...   0.003665      0.0        0.0\n",
      "1              0.007064   0.009644     0.560614  ...   0.002781      0.0        0.0\n",
      "2              0.003770   0.006131     0.557329  ...   0.005336      0.0        0.0\n",
      "3              0.001576   0.000296     0.545391  ...   0.007954      0.0        0.0\n",
      "4              0.003795   0.003808     0.541789  ...   0.006374      0.0        0.0\n",
      "\n",
      "[5 rows x 462 columns]\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LinearRegression                    | -3.4657            | 1.7840             | 1365.8009          | 5050123.7910       | 2247.2480          | 81.76              | 134.53             |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Ridge                               | 0.6512             | 1.0612             | 409.4347           | 394422.4845        | 628.0306           | 24.51              | 37.60              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Lasso                               | 0.6305             | 1.0649             | 421.9983           | 417853.7224        | 646.4161           | 25.26              | 38.70              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ElasticNet                          | 0.6028             | 1.0697             | 473.8482           | 449155.2766        | 670.1905           | 28.37              | 40.12              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| BayesianRidge                       | 0.6652             | 1.0588             | 403.6636           | 378566.5220        | 615.2776           | 24.16              | 36.83              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LassoLars                           | 0.6291             | 1.0651             | 415.8703           | 419397.7095        | 647.6092           | 24.90              | 38.77              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| PassiveAggressiveRegressor          | 0.6286             | 1.0652             | 398.0228           | 420033.0174        | 648.0995           | 23.83              | 38.80              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| TheilSenRegressor                   | -3.4926            | 1.7888             | 1370.6626          | 5080584.5509       | 2254.0152          | 82.05              | 134.93             |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HuberRegressor                      | 0.5995             | 1.0703             | 439.0697           | 452967.6443        | 673.0287           | 26.28              | 40.29              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| OrthogonalMatchingPursuit           | 0.6153             | 1.0675             | 451.9825           | 435070.5904        | 659.5988           | 27.06              | 39.49              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| TweedieRegressor                    | 0.5580             | 1.0776             | 519.0364           | 499806.1407        | 706.9697           | 31.07              | 42.32              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| PoissonRegressor                    | 0.6140             | 1.0678             | 427.9145           | 436564.8456        | 660.7305           | 25.62              | 39.55              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GammaRegressor                      | 0.5702             | 1.0755             | 494.4610           | 486079.6935        | 697.1942           | 29.60              | 41.74              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForestRegressor               | 0.6802             | 1.0562             | 387.7780           | 361693.6865        | 601.4097           | 23.21              | 36.00              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.7020             | 1.0523             | 359.0509           | 337038.9564        | 580.5506           | 21.49              | 34.75              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoostingRegressor           | 0.6851             | 1.0553             | 389.1290           | 356137.3803        | 596.7725           | 23.29              | 35.73              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBRegressor                        | 0.6649             | 1.0588             | 395.6933           | 378996.4887        | 615.6269           | 23.69              | 36.85              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 40845\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score 1541.521429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| lgb.LGBMRegressor                   | 0.6504             | 1.0614             | 386.9335           | 395341.3405        | 628.7618           | 23.16              | 37.64              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoostRegressor                   | 0.6915             | 1.0542             | 455.6246           | 348844.0952        | 590.6303           | 27.28              | 35.36              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.6354             | 1.0640             | 390.4504           | 412355.1536        | 642.1489           | 23.37              | 38.44              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LinearSVR                           | -0.1777            | 1.2068             | 808.9096           | 1331850.6024       | 1154.0583          | 48.42              | 69.09              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR                                 | -0.0217            | 1.1794             | 870.2700           | 1155410.2234       | 1074.9001          | 52.10              | 64.35              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| NuSVR                               | -0.0028            | 1.1761             | 867.5193           | 1134097.1824       | 1064.9400          | 51.93              | 63.75              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| DecisionTreeRegressor               | 0.4640             | 1.0941             | 463.6286           | 606095.2286        | 778.5212           | 27.75              | 46.61              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreeRegressor                  | 0.3710             | 1.1104             | 501.0143           | 711372.6714        | 843.4291           | 29.99              | 50.49              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| KNeighborsRegressor                 | 0.6733             | 1.0574             | 391.3657           | 369468.3063        | 607.8390           | 23.43              | 36.39              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GaussianProcessRegressor            | 0.6415             | 1.0629             | 450.4148           | 405381.7592        | 636.6960           | 26.96              | 38.12              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "模型评估结果已保存到 ./模型评估/建设用地/单模型/公服用地模型评估.csv\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training.py --data_path \"特征工程处理csv\\公服用地_修正_处理后.csv\" \\\n",
    "                        --model_save_path \"./model/建设用地/单模型/公服用地\" \\\n",
    "                        --comparison_save_path \"./模型评估/建设用地/单模型/公服用地模型评估.csv\" \\\n",
    "                        --target \"Y\" \\\n",
    "                        --test_size 0.2 \\\n",
    "                        --random_state 45 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 公服用地-bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Bagging 模型: PassiveAggressiveRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| PassiveAggressiveRegressor          | 0.6064             | 1.0689             | 456.5990           | 445123.5290        | 667.1758           | 27.33              | 39.94              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: TheilSenRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| TheilSenRegressor                   | 0.5445             | 1.0798             | 542.6287           | 515165.3794        | 717.7502           | 32.48              | 42.97              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: HuberRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HuberRegressor                      | 0.6008             | 1.0699             | 451.8849           | 451473.5881        | 671.9178           | 27.05              | 40.22              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: OrthogonalMatchingPursuit\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| OrthogonalMatchingPursuit           | 0.6169             | 1.0671             | 429.0734           | 433221.2286        | 658.1954           | 25.69              | 39.40              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: TweedieRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| TweedieRegressor                    | 0.6558             | 1.0603             | 410.8728           | 389301.6490        | 623.9404           | 24.60              | 37.35              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: PoissonRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| PoissonRegressor                    | 0.3333             | 1.1168             | 492.8932           | 754002.5711        | 868.3332           | 29.51              | 51.98              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: GammaRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GammaRegressor                      | 0.6501             | 1.0613             | 406.9832           | 395650.8359        | 629.0078           | 24.36              | 37.65              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                 模型名称       R^2  ...       %MAE      %RMSE\n",
      "4            TweedieRegressor_bagging  0.655753  ...  24.596431  37.351477\n",
      "6              GammaRegressor_bagging  0.650139  ...  24.363584  37.654831\n",
      "3   OrthogonalMatchingPursuit_bagging  0.616916  ...  25.685984  39.402114\n",
      "0  PassiveAggressiveRegressor_bagging  0.606392  ...  27.333773  39.939713\n",
      "2              HuberRegressor_bagging  0.600777  ...  27.051570  40.223591\n",
      "1           TheilSenRegressor_bagging  0.544456  ...  32.483845  42.967293\n",
      "5            PoissonRegressor_bagging  0.333260  ...  29.506488  51.981771\n",
      "\n",
      "[7 rows x 7 columns]\n",
      "Bagging袋装法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    }
   ],
   "source": [
    "# 林地\n",
    "!python ./tools/model_training_bagging.py --data_path \"特征工程处理csv/公服用地_修正_处理后.csv\" \\\n",
    "                                         --model_save_path \"./model/建设用地/Bagging模型/公服用地\" \\\n",
    "                                         --comparison_save_path \"./模型评估/建设用地/Bagging模型/公服用地Bagging模型评估.csv\" \\\n",
    "                                         --target \"Y\" \\\n",
    "                                         --n_estimators 200 \\\n",
    "                                         --test_size 0.2 \\\n",
    "                                             --random_state 45 \\\n",
    "                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 草地-bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
    "    | Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
    "    | NuSVR                               | 0.8234             | 1.0086             | 0.0890             | 0.0136             | 0.1167             | 5.13               | 6.72               |\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Bagging 模型: NuSVR\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| NuSVR                               | 0.8234             | 1.0086             | 0.0890             | 0.0136             | 0.1167             | 5.13               | 6.72               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "            模型名称     R^2       MAE       MSE      RMSE     %MAE    %RMSE\n",
      "0  NuSVR_bagging  0.8234  0.089008  0.013612  0.116671  5.12903  6.72309\n",
      "Bagging袋装法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_bagging.py --data_path \"特征工程处理csv\\草地_修正_处理后.csv\" \\\n",
    "                                             --model_save_path \"./model/农用地/Bagging模型/草地\" \\\n",
    "                                             --comparison_save_path \"./模型评估/农用地/Bagging模型/草地Bagging模型评估.csv\" \\\n",
    "                                             --target \"Y\" \\\n",
    "                                             --n_estimators 10 \\\n",
    "                                             --test_size 0.2 \\\n",
    "                                             --random_state 45 \\\n",
    "                                             --model_list \"NuSVR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 林地-bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
    "    | Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
    "    | GradientBoostingRegressor           | 0.8276             | 1.1034             | 0.1322             | 0.0357             | 0.1889             | 8.37               | 11.97              |\n",
    "    +-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Bagging 模型: GradientBoostingRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoostingRegressor           | 0.8276             | 1.1034             | 0.1322             | 0.0357             | 0.1889             | 8.37               | 11.97              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                模型名称       R^2  ...      %MAE      %RMSE\n",
      "0  GradientBoostingRegressor_bagging  0.827644  ...  8.374785  11.971851\n",
      "\n",
      "[1 rows x 7 columns]\n",
      "Bagging袋装法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 林地\n",
    "!python ./tools/model_training_bagging.py --data_path \"特征工程处理csv/林地_修正_处理后.csv\" \\\n",
    "                                         --model_save_path \"./model/农用地/Bagging模型/林地\" \\\n",
    "                                         --comparison_save_path \"./模型评估/农用地/Bagging模型/林地Bagging模型评估.csv\" \\\n",
    "                                         --target \"Y\" \\\n",
    "                                         --n_estimators 10 \\\n",
    "                                         --test_size 0.2 \\\n",
    "                                             --random_state 45 \\\n",
    "                                             --model_list  \"GradientBoostingRegressor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 耕地-bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Bagging 模型: RandomForestRegressor"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForestRegressor               | 0.7742             | -0.0231            | 0.2467             | 0.1244             | 0.3528             | 5.17               | 7.39               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: ExtraTreesRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.7851             | 0.0263             | 0.2371             | 0.1184             | 0.3442             | 4.97               | 7.21               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: lgb.LGBMRegressor\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.747745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.725425\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749242\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734822\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.724767\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.732020\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.767048\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.735213\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.744501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.758143\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| lgb.LGBMRegressor                   | 0.7764             | -0.0133            | 0.2377             | 0.1232             | 0.3511             | 4.98               | 7.36               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: AdaBoostRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoostRegressor                   | 0.6720             | -0.4861            | 0.3391             | 0.1808             | 0.4252             | 7.11               | 8.91               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: ExtraTreeRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreeRegressor                  | 0.7681             | -0.0506            | 0.2463             | 0.1278             | 0.3575             | 5.16               | 7.49               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                            模型名称       R^2  ...      %MAE     %RMSE\n",
      "1    ExtraTreesRegressor_bagging  0.785081  ...  4.970451  7.213605\n",
      "2      lgb.LGBMRegressor_bagging  0.776361  ...  4.981759  7.358484\n",
      "0  RandomForestRegressor_bagging  0.774199  ...  5.170997  7.393979\n",
      "4     ExtraTreeRegressor_bagging  0.768122  ...  5.163066  7.492816\n",
      "3      AdaBoostRegressor_bagging  0.671990  ...  7.106722  8.911661\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "Bagging袋装法集成模型训练完成操作\n"
     ]
    }
   ],
   "source": [
    "# 耕地\n",
    "!python ./tools/model_training_bagging.py --data_path \"特征工程处理csv/耕地_修正_处理后.csv\" \\\n",
    "                                         --model_save_path \"./model/农用地/Bagging模型/耕地\" \\\n",
    "                                         --comparison_save_path \"./模型评估/农用地/Bagging模型/耕地Bagging模型评估.csv\" \\\n",
    "                                         --target \"Y\" \\\n",
    "                                         --n_estimators 10 \\\n",
    "                                         --test_size 0.2 \\\n",
    "                                         --random_state 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 园地-bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         距五金、机电、仪器仪表的距离  距行业性团体的距离  距汽车销售及服务的距离  ...  住、宿POI核密度   木材加工核密度  轨道S1号线核密度\n",
      "pointID                                          ...                                \n",
      "0              1.029268   0.294803     1.484013  ...  -0.146376 -0.053184   -0.03518\n",
      "1              0.409153  -0.255744    -0.720902  ...  -0.146376 -0.053184   -0.03518\n",
      "2              0.413329  -0.251959    -0.708104  ...   0.202828 -0.053184   -0.03518\n",
      "3              0.445328  -0.223588    -0.707317  ...   2.961473 -0.053184   -0.03518\n",
      "4              0.446416  -0.222801    -0.736050  ...  -0.060163 -0.053184   -0.03518\n",
      "...                 ...        ...          ...  ...        ...       ...        ...\n",
      "803           -0.424212   0.135477     0.780514  ...  -0.146376 -0.053184   -0.03518\n",
      "804           -0.635104   0.501327     1.515690  ...  -0.146376 -0.053184   -0.03518\n",
      "805           -0.208089   0.152037     0.932162  ...  -0.146376 -0.053184   -0.03518\n",
      "806           -0.380780   0.172860     1.622021  ...  -0.146376 -0.053184   -0.03518\n",
      "807            0.120558   0.171870     1.129254  ...  -0.146376 -0.053184   -0.03518\n",
      "\n",
      "[808 rows x 457 columns]\n",
      "训练 Bagging 模型: ExtraTreesRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.7663             | 1.1271             | 0.2025             | 0.1114             | 0.3337             | 4.82               | 7.94               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                          模型名称       R^2  ...      %MAE     %RMSE\n",
      "0  ExtraTreesRegressor_bagging  0.766336  ...  4.820434  7.943281\n",
      "\n",
      "[1 rows x 7 columns]\n",
      "Bagging袋装法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 园地\n",
    "!python ./tools/model_training_bagging.py --data_path \"特征工程处理csv/园地_修正_处理后.csv\" \\\n",
    "                                         --model_save_path \"./model/农用地/Bagging模型/园地\" \\\n",
    "                                         --comparison_save_path \"./模型评估/农用地/Bagging模型/园地Bagging模型评估.csv\" \\\n",
    "                                         --target \"Y\" \\\n",
    "                                         --n_estimators 10 \\\n",
    "                                         --test_size 0.2 \\\n",
    "                                         --random_state 45\n",
    "                                        #  --model_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 坑塘水面-bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Bagging 模型: RandomForestRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForestRegressor               | 0.7692             | 1.0296             | 0.2649             | 0.1207             | 0.3474             | 4.29               | 5.63               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: ExtraTreesRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreesRegressor                 | 0.7314             | 1.0344             | 0.2671             | 0.1405             | 0.3749             | 4.33               | 6.07               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: lgb.LGBMRegressor\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.314749\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.220036\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.378664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.228936\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.261751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.305374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.228157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.289484\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.269304\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30500\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.296909\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| lgb.LGBMRegressor                   | 0.7628             | 1.0304             | 0.2587             | 0.1241             | 0.3522             | 4.19               | 5.71               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: AdaBoostRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoostRegressor                   | 0.7583             | 1.0310             | 0.2759             | 0.1264             | 0.3556             | 4.47               | 5.76               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: ExtraTreeRegressor\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTreeRegressor                  | 0.7037             | 1.0380             | 0.2856             | 0.1550             | 0.3937             | 4.63               | 6.38               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                            模型名称       R^2  ...      %MAE     %RMSE\n",
      "0  RandomForestRegressor_bagging  0.769236  ...  4.291703  5.628774\n",
      "2      lgb.LGBMRegressor_bagging  0.762813  ...  4.191946  5.706567\n",
      "3      AdaBoostRegressor_bagging  0.758299  ...  4.470731  5.760612\n",
      "1    ExtraTreesRegressor_bagging  0.731359  ...  4.328040  6.073173\n",
      "4     ExtraTreeRegressor_bagging  0.703659  ...  4.626341  6.378600\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "Bagging袋装法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 坑塘水面\n",
    "!python ./tools/model_training_bagging.py --data_path \"特征工程处理csv/坑塘水面_修正_处理后.csv\" \\\n",
    "                                         --model_save_path \"./model/农用地/Bagging模型/坑塘水面\" \\\n",
    "                                         --comparison_save_path \"./模型评估/农用地/Bagging模型/坑塘水面Bagging模型评估.csv\" \\\n",
    "                                         --target \"Y\" \\\n",
    "                                         --n_estimators 10 \\\n",
    "                                         --test_size 0.2 \\\n",
    "                                         --random_state 45\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设施农用地-bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Bagging 模型: Ridge\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Ridge                               | 0.6393             | 1.0174             | 0.4513             | 0.4108             | 0.6409             | 6.57               | 9.33               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Bagging 模型: BayesianRidge\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| BayesianRidge                       | 0.6343             | 1.0176             | 0.4543             | 0.4165             | 0.6454             | 6.61               | 9.39               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                    模型名称       R^2       MAE  ...      RMSE      %MAE     %RMSE\n",
      "0          Ridge_bagging  0.639329  0.451338  ...  0.640899  6.569928  9.329298\n",
      "1  BayesianRidge_bagging  0.634270  0.454277  ...  0.645379  6.612721  9.394499\n",
      "\n",
      "[2 rows x 7 columns]\n",
      "Bagging袋装法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 设施农用地\n",
    "!python ./tools/model_training_bagging.py --data_path \"特征工程处理csv/设施农用地_修正_处理后.csv\" \\\n",
    "                                         --model_save_path \"./model/农用地/Bagging模型/设施农用地\" \\\n",
    "                                         --comparison_save_path \"./模型评估/农用地/Bagging模型/设施农用地Bagging模型评估.csv\" \\\n",
    "                                         --target \"Y\" \\\n",
    "                                         --n_estimators 100 \\\n",
    "                                         --test_size 0.2 \\\n",
    "                                         --random_state 45\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 草地-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功使用 utf-8 编码读取数据。\n",
      "训练 AdaBoost 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoost                            | 0.7885             | 1.0103             | 0.1006             | 0.0163             | 0.1277             | 5.79               | 7.36               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 GradientBoosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoosting                    | 0.7369             | 1.0128             | 0.1145             | 0.0203             | 0.1424             | 6.60               | 8.21               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 HistGradientBoostingRegressor 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.7268             | 1.0133             | 0.1125             | 0.0211             | 0.1451             | 6.48               | 8.36               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 XGBoost_boosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBoost_boosting                    | 0.6037             | 1.0194             | 0.1378             | 0.0305             | 0.1748             | 7.94               | 10.07              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 LGBM_boosting 模型\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12939\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.688556\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_boosting                       | 0.7600             | 1.0117             | 0.1032             | 0.0185             | 0.1360             | 5.95               | 7.84               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                     模型名称       R^2  ...      %MAE      %RMSE\n",
      "0                       AdaBoost_boosting  0.788538  ...  5.794990   7.356812\n",
      "4                  LGBM_boosting_boosting  0.759993  ...  5.946103   7.837653\n",
      "1               GradientBoosting_boosting  0.736925  ...  6.596117   8.205661\n",
      "2  HistGradientBoostingRegressor_boosting  0.726780  ...  6.482058   8.362383\n",
      "3               XGBoost_boosting_boosting  0.603660  ...  7.940158  10.071818\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "boosting提升法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 草地\n",
    "!python ./tools/model_training_boosting.py --data_path \"特征工程处理csv/草地_修正_处理后.csv\" \\\n",
    "                                           --model_save_path \"./model/农用地/Boosting模型/草地\" \\\n",
    "                                           --comparison_save_path \"./模型评估/农用地/Boosting模型/草地Boosting模型评估.csv\" \\\n",
    "                                           --target \"Y\" \\\n",
    "                                           --num 100 \\\n",
    "                                           --test_size 0.2 \\\n",
    "                                           --random_state 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 林地-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功使用 utf-8 编码读取数据。\n",
      "训练 AdaBoost 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoost                            | 0.7974             | 1.1220             | 0.1579             | 0.0420             | 0.2048             | 10.00              | 12.98              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 GradientBoosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoosting                    | 0.7934             | 1.1244             | 0.1429             | 0.0428             | 0.2068             | 9.06               | 13.11              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 HistGradientBoostingRegressor 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.8087             | 1.1152             | 0.1361             | 0.0396             | 0.1990             | 8.63               | 12.61              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 XGBoost_boosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBoost_boosting                    | 0.7937             | 1.1242             | 0.1419             | 0.0427             | 0.2067             | 8.99               | 13.10              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 LGBM_boosting 模型\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96008\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.595699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_boosting                       | 0.7959             | 1.1229             | 0.1394             | 0.0423             | 0.2056             | 8.83               | 13.03              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                     模型名称       R^2  ...       %MAE      %RMSE\n",
      "2  HistGradientBoostingRegressor_boosting  0.808739  ...   8.627098  12.611346\n",
      "0                       AdaBoost_boosting  0.797357  ...  10.004029  12.981203\n",
      "4                  LGBM_boosting_boosting  0.795915  ...   8.834408  13.027298\n",
      "3               XGBoost_boosting_boosting  0.793736  ...   8.989698  13.096656\n",
      "1               GradientBoosting_boosting  0.793409  ...   9.058940  13.107034\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "boosting提升法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 林地\n",
    "!python ./tools/model_training_boosting.py --data_path \"特征工程处理csv/林地_修正_处理后.csv\" \\\n",
    "                                           --model_save_path \"./model/农用地/Boosting模型/林地\" \\\n",
    "                                           --comparison_save_path \"./模型评估/农用地/Boosting模型/林地Boosting模型评估.csv\" \\\n",
    "                                           --target \"Y\" \\\n",
    "                                           --num 100 \\\n",
    "                                           --test_size 0.2 \\\n",
    "                                           --random_state 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 园地-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功使用 utf-8 编码读取数据。\n",
      "训练 AdaBoost 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoost                            | 0.6943             | 1.1663             | 0.2990             | 0.1457             | 0.3817             | 7.12               | 9.09               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 GradientBoosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoosting                    | 0.7044             | 1.1608             | 0.2356             | 0.1408             | 0.3753             | 5.61               | 8.93               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 HistGradientBoostingRegressor 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.7073             | 1.1592             | 0.2335             | 0.1395             | 0.3735             | 5.56               | 8.89               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 XGBoost_boosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBoost_boosting                    | 0.6202             | 1.2066             | 0.2255             | 0.1810             | 0.4254             | 5.37               | 10.13              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 LGBM_boosting 模型\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 90852\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.251943\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_boosting                       | 0.7313             | 1.1462             | 0.2300             | 0.1281             | 0.3578             | 5.47               | 8.52               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                     模型名称       R^2  ...      %MAE      %RMSE\n",
      "4                  LGBM_boosting_boosting  0.731284  ...  5.474176   8.518257\n",
      "2  HistGradientBoostingRegressor_boosting  0.707310  ...  5.558729   8.890118\n",
      "1               GradientBoosting_boosting  0.704443  ...  5.607621   8.933560\n",
      "0                       AdaBoost_boosting  0.694325  ...  7.117602   9.085180\n",
      "3               XGBoost_boosting_boosting  0.620220  ...  5.368128  10.126742\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "boosting提升法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 园地\n",
    "!python ./tools/model_training_boosting.py --data_path \"特征工程处理csv/园地_修正_处理后.csv\" \\\n",
    "                                           --model_save_path \"./model/农用地/Boosting模型/园地\" \\\n",
    "                                           --comparison_save_path \"./模型评估/农用地/Boosting模型/园地Boosting模型评估.csv\" \\\n",
    "                                           --target \"Y\" \\\n",
    "                                           --num 100 \\\n",
    "                                           --test_size 0.2 \\\n",
    "                                           --random_state 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 耕地-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功使用 utf-8 编码读取数据。\n",
      "训练 AdaBoost 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoost                            | 0.5627             | -0.9661            | 0.3699             | 0.2410             | 0.4909             | 7.75               | 10.29              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 GradientBoosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoosting                    | 0.6310             | -0.6590            | 0.2796             | 0.2033             | 0.4509             | 5.86               | 9.45               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 HistGradientBoostingRegressor 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.6877             | -0.4041            | 0.2563             | 0.1721             | 0.4149             | 5.37               | 8.70               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 XGBoost_boosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBoost_boosting                    | 0.6803             | -0.4372            | 0.2537             | 0.1762             | 0.4197             | 5.32               | 8.80               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 LGBM_boosting 模型\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108465\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.743763\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_boosting                       | 0.6795             | -0.4409            | 0.2566             | 0.1766             | 0.4203             | 5.38               | 8.81               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                     模型名称       R^2  ...      %MAE      %RMSE\n",
      "2  HistGradientBoostingRegressor_boosting  0.687704  ...  5.371137   8.695569\n",
      "3               XGBoost_boosting_boosting  0.680345  ...  5.318541   8.797434\n",
      "4                  LGBM_boosting_boosting  0.679518  ...  5.379144   8.808806\n",
      "1               GradientBoosting_boosting  0.631011  ...  5.861121   9.451955\n",
      "0                       AdaBoost_boosting  0.562713  ...  7.752252  10.289596\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "boosting提升法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_boosting.py --data_path \"特征工程处理csv/耕地_修正_处理后.csv\" \\\n",
    "                                           --model_save_path \"./model/农用地/Boosting模型/耕地\" \\\n",
    "                                           --comparison_save_path \"./模型评估/农用地/Boosting模型/耕地Boosting模型评估.csv\" \\\n",
    "                                           --target \"Y\" \\\n",
    "                                           --num 100 \\\n",
    "                                           --test_size 0.2 \\\n",
    "                                           --random_state 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功使用 utf-8 编码读取数据。\n",
      "训练 AdaBoost 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoost                            | 0.5627             | -0.9661            | 0.3699             | 0.2410             | 0.4909             | 7.75               | 10.29              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 GradientBoosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoosting                    | 0.6310             | -0.6590            | 0.2796             | 0.2033             | 0.4509             | 5.86               | 9.45               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 HistGradientBoostingRegressor 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.6877             | -0.4041            | 0.2563             | 0.1721             | 0.4149             | 5.37               | 8.70               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 XGBoost_boosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBoost_boosting                    | 0.6803             | -0.4372            | 0.2537             | 0.1762             | 0.4197             | 5.32               | 8.80               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 LGBM_boosting 模型\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108465\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.743763\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_boosting                       | 0.6795             | -0.4409            | 0.2566             | 0.1766             | 0.4203             | 5.38               | 8.81               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                     模型名称       R^2  ...      %MAE      %RMSE\n",
      "2  HistGradientBoostingRegressor_boosting  0.687704  ...  5.371137   8.695569\n",
      "3               XGBoost_boosting_boosting  0.680345  ...  5.318541   8.797434\n",
      "4                  LGBM_boosting_boosting  0.679518  ...  5.379144   8.808806\n",
      "1               GradientBoosting_boosting  0.631011  ...  5.861121   9.451955\n",
      "0                       AdaBoost_boosting  0.562713  ...  7.752252  10.289596\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "boosting提升法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 耕地\n",
    "!python ./tools/model_training_boosting.py --data_path \"特征工程处理csv/耕地_修正_处理后.csv\" \\\n",
    "                                           --model_save_path \"./model/农用地/Boosting模型/耕地\" \\\n",
    "                                           --comparison_save_path \"./模型评估/农用地/Boosting模型/耕地Boosting模型评估.csv\" \\\n",
    "                                           --target \"Y\" \\\n",
    "                                           --num 100 \\\n",
    "                                           --test_size 0.2 \\\n",
    "                                           --random_state 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  坑塘水面-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功使用 utf-8 编码读取数据。\n",
      "训练 AdaBoost 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoost                            | 0.6746             | 1.0418             | 0.3127             | 0.1702             | 0.4126             | 5.07               | 6.68               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 GradientBoosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoosting                    | 0.6706             | 1.0423             | 0.3207             | 0.1723             | 0.4151             | 5.20               | 6.73               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 HistGradientBoostingRegressor 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.6838             | 1.0406             | 0.3135             | 0.1654             | 0.4067             | 5.08               | 6.59               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 XGBoost_boosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBoost_boosting                    | 0.6734             | 1.0419             | 0.2941             | 0.1708             | 0.4133             | 4.76               | 6.70               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 LGBM_boosting 模型\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30428\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.290576\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_boosting                       | 0.7233             | 1.0355             | 0.2865             | 0.1448             | 0.3805             | 4.64               | 6.16               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                     模型名称       R^2  ...      %MAE     %RMSE\n",
      "4                  LGBM_boosting_boosting  0.723269  ...  4.641033  6.163941\n",
      "2  HistGradientBoostingRegressor_boosting  0.683832  ...  5.079689  6.588531\n",
      "0                       AdaBoost_boosting  0.674612  ...  5.066341  6.683908\n",
      "3               XGBoost_boosting_boosting  0.673421  ...  4.764155  6.696125\n",
      "1               GradientBoosting_boosting  0.670588  ...  5.195649  6.725106\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "boosting提升法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 坑塘水面\n",
    "!python ./tools/model_training_boosting.py --data_path \"特征工程处理csv/坑塘水面_修正_处理后.csv\" \\\n",
    "                                           --model_save_path \"./model/农用地/Boosting模型/坑塘水面\" \\\n",
    "                                           --comparison_save_path \"./模型评估/农用地/Boosting模型/坑塘水面Boosting模型评估.csv\" \\\n",
    "                                           --target \"Y\" \\\n",
    "                                           --num 100 \\\n",
    "                                           --test_size 0.2 \\\n",
    "                                           --random_state 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设施农用地-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功使用 utf-8 编码读取数据。\n",
      "训练 AdaBoost 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| AdaBoost                            | 0.6689             | 1.0160             | 0.4758             | 0.3770             | 0.6140             | 6.93               | 8.94               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 GradientBoosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| GradientBoosting                    | 0.4474             | 1.0267             | 0.5599             | 0.6293             | 0.7933             | 8.15               | 11.55              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 HistGradientBoostingRegressor 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| HistGradientBoostingRegressor       | 0.5433             | 1.0220             | 0.5445             | 0.5201             | 0.7212             | 7.93               | 10.50              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 XGBoost_boosting 模型\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| XGBoost_boosting                    | 0.4847             | 1.0249             | 0.5121             | 0.5869             | 0.7661             | 7.45               | 11.15              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 LGBM_boosting 模型\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12672\n",
      "[LightGBM] [Info] Number of data points in the train set: 85, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 6.592557\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_boosting                       | 0.5860             | 1.0200             | 0.5198             | 0.4715             | 0.6867             | 7.57               | 10.00              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                     模型名称       R^2  ...      %MAE      %RMSE\n",
      "0                       AdaBoost_boosting  0.668924  ...  6.925895   8.938343\n",
      "4                  LGBM_boosting_boosting  0.585952  ...  7.565943   9.995821\n",
      "2  HistGradientBoostingRegressor_boosting  0.543339  ...  7.926710  10.497608\n",
      "3               XGBoost_boosting_boosting  0.484675  ...  7.453929  11.151510\n",
      "1               GradientBoosting_boosting  0.447412  ...  8.149809  11.547661\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "boosting提升法集成模型训练完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# 设施农用地\n",
    "!python ./tools/model_training_boosting.py --data_path \"特征工程处理csv/设施农用地_修正_处理后.csv\" \\\n",
    "                                           --model_save_path \"./model/农用地/Boosting模型/设施农用地\" \\\n",
    "                                           --comparison_save_path \"./模型评估/农用地/Boosting模型/设施农用地Boosting模型评估.csv\" \\\n",
    "                                           --target \"Y\" \\\n",
    "                                           --num 100 \\\n",
    "                                           --test_size 0.2 \\\n",
    "                                           --random_state 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.6991             | 1.0147             | 0.1229             | 0.0282             | 0.1680             | 7.01               | 9.58               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7174             | 1.0138             | 0.1176             | 0.0265             | 0.1628             | 6.71               | 9.28               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7402             | 1.0127             | 0.1183             | 0.0244             | 0.1561             | 6.75               | 8.90               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7458             | 1.0124             | 0.1085             | 0.0239             | 0.1544             | 6.19               | 8.81               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7358             | 1.0129             | 0.1121             | 0.0248             | 0.1574             | 6.39               | 8.98               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.6380             | 1.0176             | 0.1261             | 0.0340             | 0.1843             | 7.19               | 10.51              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.6949             | 1.0149             | 0.1341             | 0.0286             | 0.1692             | 7.65               | 9.65               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7162             | 1.0138             | 0.1162             | 0.0266             | 0.1632             | 6.63               | 9.30               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7441             | 1.0125             | 0.1089             | 0.0240             | 0.1550             | 6.21               | 8.84               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.6981             | 1.0147             | 0.1319             | 0.0283             | 0.1683             | 7.52               | 9.60               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7107             | 1.0141             | 0.1227             | 0.0271             | 0.1648             | 7.00               | 9.40               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7167             | 1.0138             | 0.1104             | 0.0266             | 0.1630             | 6.30               | 9.30               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.7302             | 1.0131             | 0.1202             | 0.0253             | 0.1591             | 6.85               | 9.07               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.7560             | 1.0119             | 0.1183             | 0.0229             | 0.1513             | 6.75               | 8.63               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.7729             | 1.0111             | 0.1067             | 0.0213             | 0.1460             | 6.08               | 8.32               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.6997             | 1.0146             | 0.1228             | 0.0282             | 0.1679             | 7.00               | 9.57               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7362             | 1.0129             | 0.1191             | 0.0248             | 0.1573             | 6.79               | 8.97               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7419             | 1.0126             | 0.1095             | 0.0242             | 0.1556             | 6.24               | 8.87               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7437             | 1.0125             | 0.1132             | 0.0240             | 0.1551             | 6.45               | 8.84               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7304             | 1.0131             | 0.1200             | 0.0253             | 0.1590             | 6.84               | 9.07               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7356             | 1.0129             | 0.1086             | 0.0248             | 0.1575             | 6.19               | 8.98               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7417             | 1.0126             | 0.1116             | 0.0242             | 0.1557             | 6.36               | 8.88               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7480             | 1.0123             | 0.1153             | 0.0236             | 0.1538             | 6.58               | 8.77               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7701             | 1.0112             | 0.1108             | 0.0216             | 0.1469             | 6.32               | 8.37               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7749             | 1.0110             | 0.1031             | 0.0211             | 0.1453             | 5.88               | 8.29               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.6859             | 1.0153             | 0.1348             | 0.0295             | 0.1717             | 7.69               | 9.79               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7070             | 1.0143             | 0.1176             | 0.0275             | 0.1658             | 6.71               | 9.46               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7617             | 1.0116             | 0.1061             | 0.0224             | 0.1495             | 6.05               | 8.53               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7252             | 1.0134             | 0.1220             | 0.0258             | 0.1606             | 6.95               | 9.16               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7930             | 1.0101             | 0.1044             | 0.0194             | 0.1394             | 5.95               | 7.95               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7685             | 1.0113             | 0.0996             | 0.0217             | 0.1474             | 5.68               | 8.40               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7177             | 1.0138             | 0.1198             | 0.0265             | 0.1627             | 6.83               | 9.28               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7700             | 1.0112             | 0.1054             | 0.0216             | 0.1469             | 6.01               | 8.38               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7773             | 1.0109             | 0.1033             | 0.0209             | 0.1445             | 5.89               | 8.24               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.7775             | 1.0108             | 0.1076             | 0.0209             | 0.1445             | 6.14               | 8.24               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.7238             | 1.0135             | 0.1213             | 0.0259             | 0.1610             | 6.92               | 9.18               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.7307             | 1.0131             | 0.1098             | 0.0253             | 0.1589             | 6.26               | 9.06               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.7073             | 1.0143             | 0.1212             | 0.0275             | 0.1657             | 6.91               | 9.45               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7475             | 1.0123             | 0.1154             | 0.0237             | 0.1539             | 6.58               | 8.78               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7631             | 1.0115             | 0.1126             | 0.0222             | 0.1491             | 6.42               | 8.50               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7853             | 1.0105             | 0.1011             | 0.0201             | 0.1419             | 5.77               | 8.09               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7362             | 1.0129             | 0.1150             | 0.0247             | 0.1573             | 6.56               | 8.97               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7555             | 1.0119             | 0.1134             | 0.0229             | 0.1515             | 6.47               | 8.64               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7499             | 1.0122             | 0.1054             | 0.0235             | 0.1532             | 6.01               | 8.73               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7781             | 1.0108             | 0.1076             | 0.0208             | 0.1443             | 6.14               | 8.23               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7118             | 1.0140             | 0.1197             | 0.0270             | 0.1644             | 6.82               | 9.38               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7459             | 1.0124             | 0.1189             | 0.0238             | 0.1544             | 6.78               | 8.80               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7326             | 1.0130             | 0.1092             | 0.0251             | 0.1584             | 6.23               | 9.03               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7588             | 1.0118             | 0.1110             | 0.0226             | 0.1504             | 6.33               | 8.58               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11700\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.675783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11714\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.666114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11688\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.698333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11719\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11711\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.700932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11704\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 1.709245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11682\n",
      "[LightGBM] [Info] Number of data points in the train set: 78, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.670255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.658715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 424\n",
      "[LightGBM] [Info] Start training from score 1.685772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11844\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.696325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12959\n",
      "[LightGBM] [Info] Number of data points in the train set: 87, number of used features: 426\n",
      "[LightGBM] [Info] Start training from score 1.683921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7657             | 1.0114             | 0.1047             | 0.0220             | 0.1483             | 5.97               | 8.46               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                                 模型名称  ...                                n_model\n",
      "29                  RandomForest_stacking_stacking_30  ...                  RandomForest_stacking\n",
      "40       ExtraTrees_RandomForest_stacking_stacking_41  ...       ExtraTrees_RandomForest_stacking\n",
      "44                    ExtraTrees_stacking_stacking_45  ...                    ExtraTrees_stacking\n",
      "34                              _stacking_stacking_35  ...                              _stacking\n",
      "33                          LGBM_stacking_stacking_34  ...                          LGBM_stacking\n",
      "24                    ExtraTrees_stacking_stacking_25  ...                    ExtraTrees_stacking\n",
      "14                              _stacking_stacking_15  ...                              _stacking\n",
      "23                    ExtraTrees_stacking_stacking_24  ...                    ExtraTrees_stacking\n",
      "32                          LGBM_stacking_stacking_33  ...                          LGBM_stacking\n",
      "30                  RandomForest_stacking_stacking_31  ...                  RandomForest_stacking\n",
      "49                          LGBM_stacking_stacking_50  ...                          LGBM_stacking\n",
      "39       ExtraTrees_RandomForest_stacking_stacking_40  ...       ExtraTrees_RandomForest_stacking\n",
      "27             RandomForest_LGBM_stacking_stacking_28  ...             RandomForest_LGBM_stacking\n",
      "48                  RandomForest_stacking_stacking_49  ...                  RandomForest_stacking\n",
      "13                              _stacking_stacking_14  ...                              _stacking\n",
      "42               ExtraTrees_LGBM_stacking_stacking_43  ...               ExtraTrees_LGBM_stacking\n",
      "43               ExtraTrees_LGBM_stacking_stacking_44  ...               ExtraTrees_LGBM_stacking\n",
      "22                    ExtraTrees_stacking_stacking_23  ...                    ExtraTrees_stacking\n",
      "38       ExtraTrees_RandomForest_stacking_stacking_39  ...       ExtraTrees_RandomForest_stacking\n",
      "46             RandomForest_LGBM_stacking_stacking_47  ...             RandomForest_LGBM_stacking\n",
      "3                      ExtraTrees_stacking_stacking_4  ...                    ExtraTrees_stacking\n",
      "8                    RandomForest_stacking_stacking_9  ...                  RandomForest_stacking\n",
      "18       ExtraTrees_RandomForest_stacking_stacking_19  ...       ExtraTrees_RandomForest_stacking\n",
      "17       ExtraTrees_RandomForest_stacking_stacking_18  ...       ExtraTrees_RandomForest_stacking\n",
      "21               ExtraTrees_LGBM_stacking_stacking_22  ...               ExtraTrees_LGBM_stacking\n",
      "2                      ExtraTrees_stacking_stacking_3  ...                    ExtraTrees_stacking\n",
      "41               ExtraTrees_LGBM_stacking_stacking_42  ...               ExtraTrees_LGBM_stacking\n",
      "16       ExtraTrees_RandomForest_stacking_stacking_17  ...       ExtraTrees_RandomForest_stacking\n",
      "4                      ExtraTrees_stacking_stacking_5  ...                    ExtraTrees_stacking\n",
      "20               ExtraTrees_LGBM_stacking_stacking_21  ...               ExtraTrees_LGBM_stacking\n",
      "47             RandomForest_LGBM_stacking_stacking_48  ...             RandomForest_LGBM_stacking\n",
      "36  ExtraTrees_RandomForest_LGBM_stacking_stacking_37  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "19               ExtraTrees_LGBM_stacking_stacking_20  ...               ExtraTrees_LGBM_stacking\n",
      "12                              _stacking_stacking_13  ...                              _stacking\n",
      "28                  RandomForest_stacking_stacking_29  ...                  RandomForest_stacking\n",
      "35  ExtraTrees_RandomForest_LGBM_stacking_stacking_36  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "31                          LGBM_stacking_stacking_32  ...                          LGBM_stacking\n",
      "1                 ExtraTrees_LGBM_stacking_stacking_2  ...               ExtraTrees_LGBM_stacking\n",
      "11                          LGBM_stacking_stacking_12  ...                          LGBM_stacking\n",
      "7                    RandomForest_stacking_stacking_8  ...                  RandomForest_stacking\n",
      "45             RandomForest_LGBM_stacking_stacking_46  ...             RandomForest_LGBM_stacking\n",
      "10                          LGBM_stacking_stacking_11  ...                          LGBM_stacking\n",
      "37  ExtraTrees_RandomForest_LGBM_stacking_stacking_38  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "26             RandomForest_LGBM_stacking_stacking_27  ...             RandomForest_LGBM_stacking\n",
      "15  ExtraTrees_RandomForest_LGBM_stacking_stacking_16  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "0         ExtraTrees_RandomForest_stacking_stacking_1  ...       ExtraTrees_RandomForest_stacking\n",
      "9                           LGBM_stacking_stacking_10  ...                          LGBM_stacking\n",
      "6                    RandomForest_stacking_stacking_7  ...                  RandomForest_stacking\n",
      "25             RandomForest_LGBM_stacking_stacking_26  ...             RandomForest_LGBM_stacking\n",
      "5               RandomForest_LGBM_stacking_stacking_6  ...             RandomForest_LGBM_stacking\n",
      "\n",
      "[50 rows x 8 columns]\n",
      "完成操作\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_stacking.py \\\n",
    "    --data_path \"特征工程处理csv/草地_修正_处理后.csv\" \\\n",
    "    --model_save_path \"./model/农用地/Stacking模型/草地\" \\\n",
    "    --output_dir \"./模型评估/农用地/Stacking模型/草地\" \\\n",
    "    --comparison_save_path \"./模型评估/农用地/Stacking模型/草地Stacking模型对比.csv\" \\\n",
    "    --min_len 2 \\\n",
    "    --max_len 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.8363             | 1.0982             | 0.1207             | 0.0353             | 0.1878             | 7.64               | 11.88              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.8607             | 1.0836             | 0.1212             | 0.0300             | 0.1732             | 7.67               | 10.96              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.8625             | 1.0825             | 0.1191             | 0.0296             | 0.1721             | 7.54               | 10.89              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.8601             | 1.0840             | 0.1198             | 0.0301             | 0.1736             | 7.58               | 10.99              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.8418             | 1.0949             | 0.1240             | 0.0341             | 0.1846             | 7.85               | 11.68              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.8331             | 1.1001             | 0.1284             | 0.0359             | 0.1896             | 8.12               | 12.00              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.8508             | 1.0895             | 0.1215             | 0.0321             | 0.1792             | 7.69               | 11.34              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.8448             | 1.0931             | 0.1258             | 0.0334             | 0.1828             | 7.96               | 11.57              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.8123             | 1.1126             | 0.1342             | 0.0404             | 0.2011             | 8.49               | 12.72              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.8601             | 1.0839             | 0.1201             | 0.0301             | 0.1736             | 7.60               | 10.98              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.8573             | 1.0856             | 0.1247             | 0.0307             | 0.1753             | 7.89               | 11.09              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.8460             | 1.0924             | 0.1285             | 0.0332             | 0.1821             | 8.14               | 11.52              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.8592             | 1.0845             | 0.1217             | 0.0303             | 0.1741             | 7.70               | 11.02              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.8615             | 1.0831             | 0.1208             | 0.0298             | 0.1727             | 7.64               | 10.93              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.8538             | 1.0877             | 0.1251             | 0.0315             | 0.1774             | 7.92               | 11.23              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.8508             | 1.0895             | 0.1192             | 0.0321             | 0.1792             | 7.54               | 11.34              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.8579             | 1.0853             | 0.1170             | 0.0306             | 0.1749             | 7.40               | 11.07              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.8550             | 1.0870             | 0.1191             | 0.0312             | 0.1767             | 7.53               | 11.18              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.8408             | 1.0955             | 0.1202             | 0.0343             | 0.1851             | 7.61               | 11.72              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.8653             | 1.0808             | 0.1167             | 0.0290             | 0.1703             | 7.38               | 10.78              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.8655             | 1.0807             | 0.1189             | 0.0290             | 0.1702             | 7.52               | 10.77              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.8622             | 1.0827             | 0.1202             | 0.0297             | 0.1723             | 7.61               | 10.90              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.8650             | 1.0810             | 0.1178             | 0.0291             | 0.1705             | 7.45               | 10.79              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.8653             | 1.0808             | 0.1172             | 0.0290             | 0.1703             | 7.42               | 10.78              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.8634             | 1.0820             | 0.1189             | 0.0294             | 0.1715             | 7.53               | 10.85              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.8554             | 1.0868             | 0.1184             | 0.0311             | 0.1765             | 7.50               | 11.17              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.8521             | 1.0887             | 0.1236             | 0.0318             | 0.1785             | 7.82               | 11.29              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.8376             | 1.0975             | 0.1265             | 0.0350             | 0.1870             | 8.00               | 11.84              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.8555             | 1.0867             | 0.1196             | 0.0311             | 0.1764             | 7.57               | 11.16              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.8552             | 1.0869             | 0.1199             | 0.0312             | 0.1766             | 7.59               | 11.18              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.8503             | 1.0898             | 0.1245             | 0.0322             | 0.1796             | 7.88               | 11.36              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.8627             | 1.0824             | 0.1191             | 0.0296             | 0.1719             | 7.54               | 10.88              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.8628             | 1.0823             | 0.1195             | 0.0295             | 0.1719             | 7.56               | 10.88              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.8612             | 1.0833             | 0.1236             | 0.0299             | 0.1729             | 7.82               | 10.94              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.8627             | 1.0824             | 0.1203             | 0.0296             | 0.1720             | 7.61               | 10.88              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.8604             | 1.0838             | 0.1154             | 0.0301             | 0.1734             | 7.31               | 10.97              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.8589             | 1.0846             | 0.1184             | 0.0304             | 0.1743             | 7.49               | 11.03              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.8518             | 1.0889             | 0.1189             | 0.0319             | 0.1787             | 7.53               | 11.31              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.8604             | 1.0838             | 0.1166             | 0.0301             | 0.1734             | 7.38               | 10.97              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.8573             | 1.0856             | 0.1171             | 0.0307             | 0.1753             | 7.41               | 11.10              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.8566             | 1.0861             | 0.1188             | 0.0309             | 0.1758             | 7.52               | 11.12              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.8668             | 1.0799             | 0.1165             | 0.0287             | 0.1694             | 7.38               | 10.72              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.8664             | 1.0802             | 0.1166             | 0.0288             | 0.1696             | 7.38               | 10.74              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.8658             | 1.0805             | 0.1189             | 0.0289             | 0.1700             | 7.52               | 10.76              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.8661             | 1.0803             | 0.1176             | 0.0288             | 0.1698             | 7.44               | 10.75              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.8582             | 1.0851             | 0.1180             | 0.0305             | 0.1747             | 7.47               | 11.06              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.8579             | 1.0852             | 0.1177             | 0.0306             | 0.1749             | 7.45               | 11.07              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.8534             | 1.0879             | 0.1232             | 0.0316             | 0.1777             | 7.80               | 11.24              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.8591             | 1.0845             | 0.1186             | 0.0303             | 0.1742             | 7.50               | 11.02              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86570\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.587142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86573\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.594396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86543\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.585946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86569\n",
      "[LightGBM] [Info] Number of data points in the train set: 615, number of used features: 431\n",
      "[LightGBM] [Info] Start training from score 1.590720\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86721\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.606837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86678\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.598893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86714\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.602118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86709\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.590675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86689\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.607141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86679\n",
      "[LightGBM] [Info] Number of data points in the train set: 616, number of used features: 430\n",
      "[LightGBM] [Info] Start training from score 1.587751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96237\n",
      "[LightGBM] [Info] Number of data points in the train set: 684, number of used features: 432\n",
      "[LightGBM] [Info] Start training from score 1.595165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.8634             | 1.0819             | 0.1190             | 0.0294             | 0.1715             | 7.53               | 10.85              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                                 模型名称  ...                                n_model\n",
      "41               ExtraTrees_LGBM_stacking_stacking_42  ...               ExtraTrees_LGBM_stacking\n",
      "42               ExtraTrees_LGBM_stacking_stacking_43  ...               ExtraTrees_LGBM_stacking\n",
      "44                    ExtraTrees_stacking_stacking_45  ...                    ExtraTrees_stacking\n",
      "43               ExtraTrees_LGBM_stacking_stacking_44  ...               ExtraTrees_LGBM_stacking\n",
      "20               ExtraTrees_LGBM_stacking_stacking_21  ...               ExtraTrees_LGBM_stacking\n",
      "19               ExtraTrees_LGBM_stacking_stacking_20  ...               ExtraTrees_LGBM_stacking\n",
      "23                    ExtraTrees_stacking_stacking_24  ...                    ExtraTrees_stacking\n",
      "22                    ExtraTrees_stacking_stacking_23  ...                    ExtraTrees_stacking\n",
      "49                          LGBM_stacking_stacking_50  ...                          LGBM_stacking\n",
      "24                    ExtraTrees_stacking_stacking_25  ...                    ExtraTrees_stacking\n",
      "32                          LGBM_stacking_stacking_33  ...                          LGBM_stacking\n",
      "31                          LGBM_stacking_stacking_32  ...                          LGBM_stacking\n",
      "34                              _stacking_stacking_35  ...                              _stacking\n",
      "2                      ExtraTrees_stacking_stacking_3  ...                    ExtraTrees_stacking\n",
      "21               ExtraTrees_LGBM_stacking_stacking_22  ...               ExtraTrees_LGBM_stacking\n",
      "13                              _stacking_stacking_14  ...                              _stacking\n",
      "33                          LGBM_stacking_stacking_34  ...                          LGBM_stacking\n",
      "1                 ExtraTrees_LGBM_stacking_stacking_2  ...               ExtraTrees_LGBM_stacking\n",
      "38       ExtraTrees_RandomForest_stacking_stacking_39  ...       ExtraTrees_RandomForest_stacking\n",
      "35  ExtraTrees_RandomForest_LGBM_stacking_stacking_36  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "9                           LGBM_stacking_stacking_10  ...                          LGBM_stacking\n",
      "3                      ExtraTrees_stacking_stacking_4  ...                    ExtraTrees_stacking\n",
      "12                              _stacking_stacking_13  ...                              _stacking\n",
      "48                  RandomForest_stacking_stacking_49  ...                  RandomForest_stacking\n",
      "36  ExtraTrees_RandomForest_LGBM_stacking_stacking_37  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "45             RandomForest_LGBM_stacking_stacking_46  ...             RandomForest_LGBM_stacking\n",
      "46             RandomForest_LGBM_stacking_stacking_47  ...             RandomForest_LGBM_stacking\n",
      "16       ExtraTrees_RandomForest_stacking_stacking_17  ...       ExtraTrees_RandomForest_stacking\n",
      "10                          LGBM_stacking_stacking_11  ...                          LGBM_stacking\n",
      "39       ExtraTrees_RandomForest_stacking_stacking_40  ...       ExtraTrees_RandomForest_stacking\n",
      "40       ExtraTrees_RandomForest_stacking_stacking_41  ...       ExtraTrees_RandomForest_stacking\n",
      "28                  RandomForest_stacking_stacking_29  ...                  RandomForest_stacking\n",
      "25             RandomForest_LGBM_stacking_stacking_26  ...             RandomForest_LGBM_stacking\n",
      "29                  RandomForest_stacking_stacking_30  ...                  RandomForest_stacking\n",
      "17       ExtraTrees_RandomForest_stacking_stacking_18  ...       ExtraTrees_RandomForest_stacking\n",
      "14                              _stacking_stacking_15  ...                              _stacking\n",
      "47             RandomForest_LGBM_stacking_stacking_48  ...             RandomForest_LGBM_stacking\n",
      "26             RandomForest_LGBM_stacking_stacking_27  ...             RandomForest_LGBM_stacking\n",
      "37  ExtraTrees_RandomForest_LGBM_stacking_stacking_38  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "6                    RandomForest_stacking_stacking_7  ...                  RandomForest_stacking\n",
      "15  ExtraTrees_RandomForest_LGBM_stacking_stacking_16  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "30                  RandomForest_stacking_stacking_31  ...                  RandomForest_stacking\n",
      "11                          LGBM_stacking_stacking_12  ...                          LGBM_stacking\n",
      "7                    RandomForest_stacking_stacking_8  ...                  RandomForest_stacking\n",
      "4                      ExtraTrees_stacking_stacking_5  ...                    ExtraTrees_stacking\n",
      "18       ExtraTrees_RandomForest_stacking_stacking_19  ...       ExtraTrees_RandomForest_stacking\n",
      "27             RandomForest_LGBM_stacking_stacking_28  ...             RandomForest_LGBM_stacking\n",
      "0         ExtraTrees_RandomForest_stacking_stacking_1  ...       ExtraTrees_RandomForest_stacking\n",
      "5               RandomForest_LGBM_stacking_stacking_6  ...             RandomForest_LGBM_stacking\n",
      "8                    RandomForest_stacking_stacking_9  ...                  RandomForest_stacking\n",
      "\n",
      "[50 rows x 8 columns]\n",
      "完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_stacking.py \\\n",
    "    --data_path \"特征工程处理csv/林地_修正_处理后.csv\" \\\n",
    "    --model_save_path \"./model/农用地/Stacking模型/林地\" \\\n",
    "    --output_dir \"./模型评估/农用地/Stacking模型/林地\" \\\n",
    "    --comparison_save_path \"./模型评估/农用地/Stacking模型/林地Stacking模型对比.csv\" \\\n",
    "    --min_len 2 \\\n",
    "    --max_len 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7219             | -0.2602            | 0.2562             | 0.1496             | 0.3868             | 5.36               | 8.09               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7145             | -0.2935            | 0.2675             | 0.1536             | 0.3919             | 5.60               | 8.20               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7114             | -0.3076            | 0.2588             | 0.1552             | 0.3940             | 5.41               | 8.24               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7440             | -0.1599            | 0.2561             | 0.1377             | 0.3711             | 5.36               | 7.76               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7475             | -0.1439            | 0.2510             | 0.1358             | 0.3685             | 5.25               | 7.71               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.6832             | -0.4353            | 0.2672             | 0.1704             | 0.4128             | 5.59               | 8.64               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.6914             | -0.3981            | 0.2563             | 0.1660             | 0.4074             | 5.36               | 8.52               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7353             | -0.1993            | 0.2552             | 0.1424             | 0.3773             | 5.34               | 7.89               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7222             | -0.2589            | 0.2484             | 0.1494             | 0.3866             | 5.20               | 8.09               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.6406             | -0.6285            | 0.2763             | 0.1933             | 0.4397             | 5.78               | 9.20               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7100             | -0.3141            | 0.2689             | 0.1560             | 0.3950             | 5.63               | 8.26               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7023             | -0.3486            | 0.2605             | 0.1601             | 0.4001             | 5.45               | 8.37               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.7015             | -0.3526            | 0.2611             | 0.1606             | 0.4007             | 5.46               | 8.38               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.7008             | -0.3557            | 0.2512             | 0.1609             | 0.4012             | 5.26               | 8.39               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.7593             | -0.0905            | 0.2455             | 0.1295             | 0.3598             | 5.14               | 7.53               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.7290             | -0.2278            | 0.2536             | 0.1458             | 0.3818             | 5.31               | 7.99               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7320             | -0.2143            | 0.2482             | 0.1442             | 0.3797             | 5.19               | 7.94               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7533             | -0.1180            | 0.2481             | 0.1327             | 0.3643             | 5.19               | 7.62               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7460             | -0.1507            | 0.2430             | 0.1366             | 0.3696             | 5.08               | 7.73               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7192             | -0.2721            | 0.2584             | 0.1510             | 0.3886             | 5.41               | 8.13               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7448             | -0.1565            | 0.2567             | 0.1373             | 0.3705             | 5.37               | 7.75               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7383             | -0.1857            | 0.2521             | 0.1408             | 0.3752             | 5.27               | 7.85               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7411             | -0.1731            | 0.2522             | 0.1393             | 0.3732             | 5.28               | 7.81               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7410             | -0.1735            | 0.2437             | 0.1393             | 0.3732             | 5.10               | 7.81               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7603             | -0.0861            | 0.2449             | 0.1289             | 0.3591             | 5.12               | 7.51               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.6956             | -0.3790            | 0.2569             | 0.1637             | 0.4046             | 5.38               | 8.46               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7331             | -0.2092            | 0.2557             | 0.1435             | 0.3789             | 5.35               | 7.93               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7254             | -0.2443            | 0.2470             | 0.1477             | 0.3843             | 5.17               | 8.04               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7305             | -0.2209            | 0.2516             | 0.1449             | 0.3807             | 5.26               | 7.96               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7274             | -0.2351            | 0.2447             | 0.1466             | 0.3829             | 5.12               | 8.01               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7556             | -0.1072            | 0.2420             | 0.1314             | 0.3625             | 5.06               | 7.58               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7070             | -0.3277            | 0.2641             | 0.1576             | 0.3970             | 5.53               | 8.31               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.6985             | -0.3660            | 0.2578             | 0.1622             | 0.4027             | 5.39               | 8.42               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7537             | -0.1157            | 0.2524             | 0.1324             | 0.3639             | 5.28               | 7.61               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: _stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| _stacking                           | 0.7448             | -0.1561            | 0.2434             | 0.1372             | 0.3705             | 5.09               | 7.75               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.7330             | -0.2097            | 0.2487             | 0.1436             | 0.3790             | 5.20               | 7.93               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.7518             | -0.1246            | 0.2488             | 0.1335             | 0.3654             | 5.21               | 7.64               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.7409             | -0.1741            | 0.2459             | 0.1394             | 0.3733             | 5.14               | 7.81               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7490             | -0.1370            | 0.2459             | 0.1350             | 0.3674             | 5.14               | 7.69               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7533             | -0.1175            | 0.2391             | 0.1327             | 0.3642             | 5.00               | 7.62               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7621             | -0.0781            | 0.2428             | 0.1280             | 0.3577             | 5.08               | 7.48               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7417             | -0.1704            | 0.2536             | 0.1389             | 0.3728             | 5.31               | 7.80               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7460             | -0.1506            | 0.2451             | 0.1366             | 0.3696             | 5.13               | 7.73               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7594             | -0.0900            | 0.2481             | 0.1294             | 0.3597             | 5.19               | 7.53               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_stacking                 | 0.7561             | -0.1050            | 0.2436             | 0.1312             | 0.3622             | 5.10               | 7.58               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7297             | -0.2246            | 0.2526             | 0.1454             | 0.3813             | 5.28               | 7.98               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7282             | -0.2317            | 0.2461             | 0.1462             | 0.3824             | 5.15               | 8.00               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7437             | -0.1612            | 0.2462             | 0.1379             | 0.3713             | 5.15               | 7.77               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_stacking               | 0.7524             | -0.1219            | 0.2400             | 0.1332             | 0.3649             | 5.02               | 7.64               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.749459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108632\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.736541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.733799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108623\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.734059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.746236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108650\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2122, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.742093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.740764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2123, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 4.748970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 108761\n",
      "[LightGBM] [Info] Number of data points in the train set: 2358, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 4.741515\n",
      "训练 Stacking 模型: LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_stacking                       | 0.7519             | -0.1239            | 0.2474             | 0.1334             | 0.3653             | 5.18               | 7.64               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                                 模型名称  ...                                n_model\n",
      "40       ExtraTrees_RandomForest_stacking_stacking_41  ...       ExtraTrees_RandomForest_stacking\n",
      "24                    ExtraTrees_stacking_stacking_25  ...                    ExtraTrees_stacking\n",
      "43               ExtraTrees_LGBM_stacking_stacking_44  ...               ExtraTrees_LGBM_stacking\n",
      "14                              _stacking_stacking_15  ...                              _stacking\n",
      "44                    ExtraTrees_stacking_stacking_45  ...                    ExtraTrees_stacking\n",
      "30                  RandomForest_stacking_stacking_31  ...                  RandomForest_stacking\n",
      "33                          LGBM_stacking_stacking_34  ...                          LGBM_stacking\n",
      "39       ExtraTrees_RandomForest_stacking_stacking_40  ...       ExtraTrees_RandomForest_stacking\n",
      "17       ExtraTrees_RandomForest_stacking_stacking_18  ...       ExtraTrees_RandomForest_stacking\n",
      "48                  RandomForest_stacking_stacking_49  ...                  RandomForest_stacking\n",
      "49                          LGBM_stacking_stacking_50  ...                          LGBM_stacking\n",
      "36  ExtraTrees_RandomForest_LGBM_stacking_stacking_37  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "38       ExtraTrees_RandomForest_stacking_stacking_39  ...       ExtraTrees_RandomForest_stacking\n",
      "4                      ExtraTrees_stacking_stacking_5  ...                    ExtraTrees_stacking\n",
      "42               ExtraTrees_LGBM_stacking_stacking_43  ...               ExtraTrees_LGBM_stacking\n",
      "18       ExtraTrees_RandomForest_stacking_stacking_19  ...       ExtraTrees_RandomForest_stacking\n",
      "34                              _stacking_stacking_35  ...                              _stacking\n",
      "20               ExtraTrees_LGBM_stacking_stacking_21  ...               ExtraTrees_LGBM_stacking\n",
      "3                      ExtraTrees_stacking_stacking_4  ...                    ExtraTrees_stacking\n",
      "47             RandomForest_LGBM_stacking_stacking_48  ...             RandomForest_LGBM_stacking\n",
      "41               ExtraTrees_LGBM_stacking_stacking_42  ...               ExtraTrees_LGBM_stacking\n",
      "22                    ExtraTrees_stacking_stacking_23  ...                    ExtraTrees_stacking\n",
      "23                    ExtraTrees_stacking_stacking_24  ...                    ExtraTrees_stacking\n",
      "37  ExtraTrees_RandomForest_LGBM_stacking_stacking_38  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "21               ExtraTrees_LGBM_stacking_stacking_22  ...               ExtraTrees_LGBM_stacking\n",
      "7                    RandomForest_stacking_stacking_8  ...                  RandomForest_stacking\n",
      "26             RandomForest_LGBM_stacking_stacking_27  ...             RandomForest_LGBM_stacking\n",
      "35  ExtraTrees_RandomForest_LGBM_stacking_stacking_36  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "16       ExtraTrees_RandomForest_stacking_stacking_17  ...       ExtraTrees_RandomForest_stacking\n",
      "28                  RandomForest_stacking_stacking_29  ...                  RandomForest_stacking\n",
      "45             RandomForest_LGBM_stacking_stacking_46  ...             RandomForest_LGBM_stacking\n",
      "15  ExtraTrees_RandomForest_LGBM_stacking_stacking_16  ...  ExtraTrees_RandomForest_LGBM_stacking\n",
      "46             RandomForest_LGBM_stacking_stacking_47  ...             RandomForest_LGBM_stacking\n",
      "29                  RandomForest_stacking_stacking_30  ...                  RandomForest_stacking\n",
      "27             RandomForest_LGBM_stacking_stacking_28  ...             RandomForest_LGBM_stacking\n",
      "8                    RandomForest_stacking_stacking_9  ...                  RandomForest_stacking\n",
      "0         ExtraTrees_RandomForest_stacking_stacking_1  ...       ExtraTrees_RandomForest_stacking\n",
      "19               ExtraTrees_LGBM_stacking_stacking_20  ...               ExtraTrees_LGBM_stacking\n",
      "1                 ExtraTrees_LGBM_stacking_stacking_2  ...               ExtraTrees_LGBM_stacking\n",
      "2                      ExtraTrees_stacking_stacking_3  ...                    ExtraTrees_stacking\n",
      "10                          LGBM_stacking_stacking_11  ...                          LGBM_stacking\n",
      "31                          LGBM_stacking_stacking_32  ...                          LGBM_stacking\n",
      "11                          LGBM_stacking_stacking_12  ...                          LGBM_stacking\n",
      "12                              _stacking_stacking_13  ...                              _stacking\n",
      "13                              _stacking_stacking_14  ...                              _stacking\n",
      "32                          LGBM_stacking_stacking_33  ...                          LGBM_stacking\n",
      "25             RandomForest_LGBM_stacking_stacking_26  ...             RandomForest_LGBM_stacking\n",
      "6                    RandomForest_stacking_stacking_7  ...                  RandomForest_stacking\n",
      "5               RandomForest_LGBM_stacking_stacking_6  ...             RandomForest_LGBM_stacking\n",
      "9                           LGBM_stacking_stacking_10  ...                          LGBM_stacking\n",
      "\n",
      "[50 rows x 8 columns]\n",
      "完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_stacking.py \\\n",
    "    --data_path \"特征工程处理csv/耕地_修正_处理后.csv\" \\\n",
    "    --model_save_path \"./model/农用地/Stacking模型/耕地\" \\\n",
    "    --output_dir \"./模型评估/农用地/Stacking模型/耕地\" \\\n",
    "    --comparison_save_path \"./模型评估/农用地/Stacking模型/耕地Stacking模型对比.csv\" \\\n",
    "    --min_len 2 \\\n",
    "    --max_len 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.7322             | 1.1452             | 0.2532             | 0.1730             | 0.4160             | 5.92               | 9.73               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.7210             | 1.1512             | 0.2561             | 0.1803             | 0.4246             | 5.99               | 9.93               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_SVR_stacking             | 0.7082             | 1.1582             | 0.2552             | 0.1885             | 0.4342             | 5.97               | 10.16              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_KNN_stacking             | 0.6990             | 1.1632             | 0.2586             | 0.1945             | 0.4410             | 6.05               | 10.32              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_DecisionTree_stacking    | 0.7095             | 1.1575             | 0.2546             | 0.1877             | 0.4332             | 5.96               | 10.13              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.7360             | 1.1431             | 0.2406             | 0.1705             | 0.4130             | 5.63               | 9.66               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_SVR_stacking           | 0.6848             | 1.1708             | 0.2414             | 0.2036             | 0.4512             | 5.65               | 10.56              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_KNN_stacking           | 0.6820             | 1.1724             | 0.2645             | 0.2054             | 0.4532             | 6.19               | 10.60              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_DecisionTree_stacking  | 0.7574             | 1.1315             | 0.2482             | 0.1567             | 0.3959             | 5.81               | 9.26               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_SVR_stacking                   | 0.6667             | 1.1807             | 0.2444             | 0.2153             | 0.4640             | 5.72               | 10.86              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_KNN_stacking                   | 0.6943             | 1.1657             | 0.2566             | 0.1975             | 0.4444             | 6.00               | 10.40              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_DecisionTree_stacking          | 0.7472             | 1.1370             | 0.2386             | 0.1633             | 0.4041             | 5.58               | 9.45               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR_KNN_stacking                    | 0.6408             | 1.1947             | 0.2570             | 0.2321             | 0.4817             | 6.01               | 11.27              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: SVR_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR_DecisionTree_stacking           | 0.7192             | 1.1522             | 0.2397             | 0.1814             | 0.4259             | 5.61               | 9.96               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: KNN_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| KNN_DecisionTree_stacking           | 0.7157             | 1.1541             | 0.2489             | 0.1837             | 0.4286             | 5.82               | 10.03              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.7523             | 1.1343             | 0.2443             | 0.1600             | 0.4000             | 5.71               | 9.36               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_SVR_stacking\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_SVR_stacking | 0.7476             | 1.1368             | 0.2442             | 0.1631             | 0.4038             | 5.71               | 9.45               |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_KNN_stacking\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_KNN_stacking | 0.7348             | 1.1437             | 0.2507             | 0.1713             | 0.4139             | 5.86               | 9.68               |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_DecisionTree_stacking\n",
      "+-----------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                         | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-----------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_DecisionTree_stacking | 0.7525             | 1.1341             | 0.2416             | 0.1599             | 0.3998             | 5.65               | 9.35               |\n",
      "+-----------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_SVR_stacking        | 0.7264             | 1.1483             | 0.2513             | 0.1768             | 0.4204             | 5.88               | 9.84               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_KNN_stacking        | 0.7192             | 1.1522             | 0.2538             | 0.1814             | 0.4259             | 5.94               | 9.96               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_DecisionTree_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_DecisionTree_stacking | 0.7262             | 1.1484             | 0.2505             | 0.1769             | 0.4206             | 5.86               | 9.84               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_SVR_KNN_stacking         | 0.7101             | 1.1571             | 0.2540             | 0.1873             | 0.4327             | 5.94               | 10.12              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_SVR_DecisionTree_stacking\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_SVR_DecisionTree_stacking | 0.7269             | 1.1481             | 0.2462             | 0.1765             | 0.4201             | 5.76               | 9.83               |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_KNN_DecisionTree_stacking\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_KNN_DecisionTree_stacking | 0.7221             | 1.1507             | 0.2476             | 0.1796             | 0.4237             | 5.79               | 9.91               |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_SVR_stacking      | 0.7199             | 1.1518             | 0.2348             | 0.1810             | 0.4254             | 5.49               | 9.95               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_KNN_stacking      | 0.7233             | 1.1500             | 0.2500             | 0.1788             | 0.4228             | 5.85               | 9.89               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_DecisionTree_stacking\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                   | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_DecisionTree_stacking | 0.7620             | 1.1290             | 0.2306             | 0.1538             | 0.3922             | 5.40               | 9.17               |\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_SVR_KNN_stacking       | 0.6894             | 1.1684             | 0.2504             | 0.2007             | 0.4480             | 5.86               | 10.48              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_SVR_DecisionTree_stacking\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                  | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_SVR_DecisionTree_stacking | 0.7438             | 1.1389             | 0.2298             | 0.1655             | 0.4068             | 5.38               | 9.52               |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_KNN_DecisionTree_stacking\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                  | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_KNN_DecisionTree_stacking | 0.7631             | 1.1284             | 0.2389             | 0.1531             | 0.3912             | 5.59               | 9.15               |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_SVR_KNN_stacking               | 0.6775             | 1.1748             | 0.2496             | 0.2083             | 0.4564             | 5.84               | 10.68              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_SVR_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_SVR_DecisionTree_stacking      | 0.7431             | 1.1393             | 0.2269             | 0.1660             | 0.4074             | 5.31               | 9.53               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_KNN_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_KNN_DecisionTree_stacking      | 0.7372             | 1.1425             | 0.2439             | 0.1698             | 0.4120             | 5.71               | 9.64               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: SVR_KNN_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR_KNN_DecisionTree_stacking       | 0.7037             | 1.1606             | 0.2455             | 0.1914             | 0.4375             | 5.74               | 10.24              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_SVR_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_SVR_stacking | 0.7543             | 1.1332             | 0.2423             | 0.1587             | 0.3984             | 5.67               | 9.32               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_KNN_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_KNN_stacking | 0.7451             | 1.1382             | 0.2464             | 0.1647             | 0.4058             | 5.76               | 9.49               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_DecisionTree_stacking\n",
      "+----------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                              | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+----------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_DecisionTree_stacking | 0.7619             | 1.1291             | 0.2368             | 0.1538             | 0.3922             | 5.54               | 9.18               |\n",
      "+----------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_SVR_KNN_stacking\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                    | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_SVR_KNN_stacking | 0.7400             | 1.1410             | 0.2478             | 0.1680             | 0.4099             | 5.80               | 9.59               |\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_SVR_DecisionTree_stacking\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                             | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_SVR_DecisionTree_stacking | 0.7597             | 1.1302             | 0.2373             | 0.1552             | 0.3940             | 5.55               | 9.22               |\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_KNN_DecisionTree_stacking\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                             | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_KNN_DecisionTree_stacking | 0.7546             | 1.1330             | 0.2405             | 0.1585             | 0.3982             | 5.63               | 9.31               |\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_SVR_KNN_stacking    | 0.7215             | 1.1510             | 0.2520             | 0.1799             | 0.4242             | 5.90               | 9.92               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_SVR_DecisionTree_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_SVR_DecisionTree_stacking | 0.7332             | 1.1446             | 0.2467             | 0.1724             | 0.4152             | 5.77               | 9.71               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_KNN_DecisionTree_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_KNN_DecisionTree_stacking | 0.7315             | 1.1455             | 0.2452             | 0.1734             | 0.4165             | 5.74               | 9.74               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_SVR_KNN_DecisionTree_stacking\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                    | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_SVR_KNN_DecisionTree_stacking | 0.7406             | 1.1406             | 0.2413             | 0.1676             | 0.4093             | 5.65               | 9.58               |\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_SVR_KNN_stacking  | 0.7122             | 1.1560             | 0.2450             | 0.1860             | 0.4312             | 5.73               | 10.09              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_SVR_DecisionTree_stacking\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                       | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_SVR_DecisionTree_stacking | 0.7406             | 1.1406             | 0.2303             | 0.1676             | 0.4094             | 5.39               | 9.58               |\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_KNN_DecisionTree_stacking\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                       | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_KNN_DecisionTree_stacking | 0.7641             | 1.1279             | 0.2394             | 0.1524             | 0.3904             | 5.60               | 9.13               |\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_SVR_KNN_DecisionTree_stacking\n",
      "+--------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                      | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_SVR_KNN_DecisionTree_stacking | 0.7311             | 1.1458             | 0.2421             | 0.1737             | 0.4168             | 5.66               | 9.75               |\n",
      "+--------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81888\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.225855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81886\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81911\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.233598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81910\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.231129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.242051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 81892\n",
      "[LightGBM] [Info] Number of data points in the train set: 581, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.237113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82040\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.225243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82062\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score 4.223905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82031\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.243294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82053\n",
      "[LightGBM] [Info] Number of data points in the train set: 582, number of used features: 439\n",
      "[LightGBM] [Info] Start training from score 4.239659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91031\n",
      "[LightGBM] [Info] Number of data points in the train set: 646, number of used features: 441\n",
      "[LightGBM] [Info] Start training from score 4.233500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_SVR_KNN_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_SVR_KNN_DecisionTree_stacking  | 0.7181             | 1.1528             | 0.2406             | 0.1821             | 0.4267             | 5.63               | 9.98               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                                 模型名称  ...                                            n_model\n",
      "47  RandomForest_LGBM_KNN_DecisionTree_stacking_st...  ...        RandomForest_LGBM_KNN_DecisionTree_stacking\n",
      "30  RandomForest_KNN_DecisionTree_stacking_stackin...  ...             RandomForest_KNN_DecisionTree_stacking\n",
      "27  RandomForest_LGBM_DecisionTree_stacking_stacki...  ...            RandomForest_LGBM_DecisionTree_stacking\n",
      "37  ExtraTrees_RandomForest_LGBM_DecisionTree_stac...  ...  ExtraTrees_RandomForest_LGBM_DecisionTree_stac...\n",
      "39  ExtraTrees_RandomForest_SVR_DecisionTree_stack...  ...  ExtraTrees_RandomForest_SVR_DecisionTree_stacking\n",
      "8       RandomForest_DecisionTree_stacking_stacking_9  ...                 RandomForest_DecisionTree_stacking\n",
      "40  ExtraTrees_RandomForest_KNN_DecisionTree_stack...  ...  ExtraTrees_RandomForest_KNN_DecisionTree_stacking\n",
      "35  ExtraTrees_RandomForest_LGBM_SVR_stacking_stac...  ...          ExtraTrees_RandomForest_LGBM_SVR_stacking\n",
      "18  ExtraTrees_RandomForest_DecisionTree_stacking_...  ...      ExtraTrees_RandomForest_DecisionTree_stacking\n",
      "15  ExtraTrees_RandomForest_LGBM_stacking_stacking_16  ...              ExtraTrees_RandomForest_LGBM_stacking\n",
      "16   ExtraTrees_RandomForest_SVR_stacking_stacking_17  ...               ExtraTrees_RandomForest_SVR_stacking\n",
      "11             LGBM_DecisionTree_stacking_stacking_12  ...                         LGBM_DecisionTree_stacking\n",
      "36  ExtraTrees_RandomForest_LGBM_KNN_stacking_stac...  ...          ExtraTrees_RandomForest_LGBM_KNN_stacking\n",
      "29  RandomForest_SVR_DecisionTree_stacking_stackin...  ...             RandomForest_SVR_DecisionTree_stacking\n",
      "32         LGBM_SVR_DecisionTree_stacking_stacking_33  ...                     LGBM_SVR_DecisionTree_stacking\n",
      "44  ExtraTrees_SVR_KNN_DecisionTree_stacking_stack...  ...           ExtraTrees_SVR_KNN_DecisionTree_stacking\n",
      "46  RandomForest_LGBM_SVR_DecisionTree_stacking_st...  ...        RandomForest_LGBM_SVR_DecisionTree_stacking\n",
      "38  ExtraTrees_RandomForest_SVR_KNN_stacking_stack...  ...           ExtraTrees_RandomForest_SVR_KNN_stacking\n",
      "33         LGBM_KNN_DecisionTree_stacking_stacking_34  ...                     LGBM_KNN_DecisionTree_stacking\n",
      "5               RandomForest_LGBM_stacking_stacking_6  ...                         RandomForest_LGBM_stacking\n",
      "17   ExtraTrees_RandomForest_KNN_stacking_stacking_18  ...               ExtraTrees_RandomForest_KNN_stacking\n",
      "42  ExtraTrees_LGBM_SVR_DecisionTree_stacking_stac...  ...          ExtraTrees_LGBM_SVR_DecisionTree_stacking\n",
      "0         ExtraTrees_RandomForest_stacking_stacking_1  ...                   ExtraTrees_RandomForest_stacking\n",
      "43  ExtraTrees_LGBM_KNN_DecisionTree_stacking_stac...  ...          ExtraTrees_LGBM_KNN_DecisionTree_stacking\n",
      "48  RandomForest_SVR_KNN_DecisionTree_stacking_sta...  ...         RandomForest_SVR_KNN_DecisionTree_stacking\n",
      "23   ExtraTrees_SVR_DecisionTree_stacking_stacking_24  ...               ExtraTrees_SVR_DecisionTree_stacking\n",
      "19           ExtraTrees_LGBM_SVR_stacking_stacking_20  ...                       ExtraTrees_LGBM_SVR_stacking\n",
      "21  ExtraTrees_LGBM_DecisionTree_stacking_stacking_22  ...              ExtraTrees_LGBM_DecisionTree_stacking\n",
      "26         RandomForest_LGBM_KNN_stacking_stacking_27  ...                     RandomForest_LGBM_KNN_stacking\n",
      "24   ExtraTrees_KNN_DecisionTree_stacking_stacking_25  ...               ExtraTrees_KNN_DecisionTree_stacking\n",
      "41       ExtraTrees_LGBM_SVR_KNN_stacking_stacking_42  ...                   ExtraTrees_LGBM_SVR_KNN_stacking\n",
      "1                 ExtraTrees_LGBM_stacking_stacking_2  ...                           ExtraTrees_LGBM_stacking\n",
      "25         RandomForest_LGBM_SVR_stacking_stacking_26  ...                     RandomForest_LGBM_SVR_stacking\n",
      "20           ExtraTrees_LGBM_KNN_stacking_stacking_21  ...                       ExtraTrees_LGBM_KNN_stacking\n",
      "13              SVR_DecisionTree_stacking_stacking_14  ...                          SVR_DecisionTree_stacking\n",
      "49     LGBM_SVR_KNN_DecisionTree_stacking_stacking_50  ...                 LGBM_SVR_KNN_DecisionTree_stacking\n",
      "14              KNN_DecisionTree_stacking_stacking_15  ...                          KNN_DecisionTree_stacking\n",
      "45     RandomForest_LGBM_SVR_KNN_stacking_stacking_46  ...                 RandomForest_LGBM_SVR_KNN_stacking\n",
      "22            ExtraTrees_SVR_KNN_stacking_stacking_23  ...                        ExtraTrees_SVR_KNN_stacking\n",
      "4         ExtraTrees_DecisionTree_stacking_stacking_5  ...                   ExtraTrees_DecisionTree_stacking\n",
      "2                  ExtraTrees_SVR_stacking_stacking_3  ...                            ExtraTrees_SVR_stacking\n",
      "34          SVR_KNN_DecisionTree_stacking_stacking_35  ...                      SVR_KNN_DecisionTree_stacking\n",
      "3                  ExtraTrees_KNN_stacking_stacking_4  ...                            ExtraTrees_KNN_stacking\n",
      "10                      LGBM_KNN_stacking_stacking_11  ...                                  LGBM_KNN_stacking\n",
      "28          RandomForest_SVR_KNN_stacking_stacking_29  ...                      RandomForest_SVR_KNN_stacking\n",
      "6                RandomForest_SVR_stacking_stacking_7  ...                          RandomForest_SVR_stacking\n",
      "7                RandomForest_KNN_stacking_stacking_8  ...                          RandomForest_KNN_stacking\n",
      "31                  LGBM_SVR_KNN_stacking_stacking_32  ...                              LGBM_SVR_KNN_stacking\n",
      "9                       LGBM_SVR_stacking_stacking_10  ...                                  LGBM_SVR_stacking\n",
      "12                       SVR_KNN_stacking_stacking_13  ...                                   SVR_KNN_stacking\n",
      "\n",
      "[50 rows x 8 columns]\n",
      "完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_stacking.py \\\n",
    "    --data_path \"特征工程处理csv/园地_修正_处理后.csv\" \\\n",
    "    --model_save_path \"./model/农用地/Stacking模型/园地\" \\\n",
    "    --output_dir \"./模型评估/农用地/Stacking模型/园地\" \\\n",
    "    --comparison_save_path \"./模型评估/农用地/Stacking模型/园地Stacking模型对比.csv\" \\\n",
    "    --min_len 2 \\\n",
    "    --max_len 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.5767             | 1.0542             | 0.2883             | 0.1988             | 0.4459             | 4.71               | 7.29               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_stacking            | 0.5323             | 1.0599             | 0.2952             | 0.2197             | 0.4687             | 4.83               | 7.66               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_SVR_stacking             | 0.7302             | 1.0346             | 0.2472             | 0.1267             | 0.3559             | 4.04               | 5.82               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_KNN_stacking             | 0.7022             | 1.0381             | 0.2631             | 0.1398             | 0.3740             | 4.30               | 6.11               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_DecisionTree_stacking    | 0.5390             | 1.0591             | 0.3116             | 0.2165             | 0.4653             | 5.10               | 7.61               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_stacking          | 0.4920             | 1.0651             | 0.3118             | 0.2386             | 0.4884             | 5.10               | 7.99               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_SVR_stacking           | 0.6220             | 1.0484             | 0.2771             | 0.1775             | 0.4213             | 4.53               | 6.89               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_KNN_stacking           | 0.5812             | 1.0536             | 0.2932             | 0.1967             | 0.4435             | 4.79               | 7.25               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_DecisionTree_stacking  | 0.5061             | 1.0633             | 0.3071             | 0.2320             | 0.4816             | 5.02               | 7.88               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_SVR_stacking                   | 0.6278             | 1.0477             | 0.2770             | 0.1748             | 0.4181             | 4.53               | 6.84               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_KNN_stacking                   | 0.5302             | 1.0602             | 0.2983             | 0.2206             | 0.4697             | 4.88               | 7.68               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_DecisionTree_stacking          | 0.4195             | 1.0744             | 0.3288             | 0.2726             | 0.5221             | 5.38               | 8.54               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR_KNN_stacking                    | 0.7293             | 1.0347             | 0.2547             | 0.1271             | 0.3566             | 4.16               | 5.83               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: SVR_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR_DecisionTree_stacking           | 0.6074             | 1.0503             | 0.2885             | 0.1844             | 0.4294             | 4.72               | 7.02               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: KNN_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| KNN_DecisionTree_stacking           | 0.5723             | 1.0548             | 0.2948             | 0.2009             | 0.4482             | 4.82               | 7.33               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_stacking | 0.5611             | 1.0562             | 0.2871             | 0.2061             | 0.4540             | 4.69               | 7.42               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_SVR_stacking\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_SVR_stacking | 0.6311             | 1.0473             | 0.2699             | 0.1733             | 0.4162             | 4.41               | 6.81               |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_KNN_stacking\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_KNN_stacking | 0.6014             | 1.0511             | 0.2811             | 0.1872             | 0.4327             | 4.60               | 7.07               |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_DecisionTree_stacking\n",
      "+-----------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                         | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-----------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_DecisionTree_stacking | 0.5443             | 1.0584             | 0.2875             | 0.2140             | 0.4626             | 4.70               | 7.56               |\n",
      "+-----------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_SVR_stacking        | 0.6571             | 1.0439             | 0.2629             | 0.1610             | 0.4013             | 4.30               | 6.56               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_KNN_stacking        | 0.5923             | 1.0522             | 0.2810             | 0.1915             | 0.4376             | 4.59               | 7.15               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_DecisionTree_stacking\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                 | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_DecisionTree_stacking | 0.5245             | 1.0609             | 0.2930             | 0.2233             | 0.4726             | 4.79               | 7.73               |\n",
      "+---------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_SVR_KNN_stacking         | 0.7300             | 1.0346             | 0.2474             | 0.1268             | 0.3561             | 4.04               | 5.82               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_SVR_DecisionTree_stacking\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_SVR_DecisionTree_stacking | 0.6417             | 1.0459             | 0.2777             | 0.1683             | 0.4102             | 4.54               | 6.71               |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_KNN_DecisionTree_stacking\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_KNN_DecisionTree_stacking | 0.6071             | 1.0503             | 0.2740             | 0.1845             | 0.4296             | 4.48               | 7.02               |\n",
      "+--------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_SVR_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_SVR_stacking      | 0.6196             | 1.0487             | 0.2772             | 0.1786             | 0.4227             | 4.53               | 6.91               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_KNN_stacking      | 0.5595             | 1.0564             | 0.2907             | 0.2069             | 0.4548             | 4.75               | 7.44               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_DecisionTree_stacking\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                   | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_DecisionTree_stacking | 0.4985             | 1.0642             | 0.3001             | 0.2355             | 0.4853             | 4.91               | 7.94               |\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_SVR_KNN_stacking       | 0.6143             | 1.0494             | 0.2811             | 0.1811             | 0.4256             | 4.60               | 6.96               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_SVR_DecisionTree_stacking\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                  | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_SVR_DecisionTree_stacking | 0.5739             | 1.0546             | 0.2840             | 0.2001             | 0.4474             | 4.64               | 7.31               |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_KNN_DecisionTree_stacking\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                  | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_KNN_DecisionTree_stacking | 0.5430             | 1.0585             | 0.2848             | 0.2146             | 0.4633             | 4.66               | 7.58               |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_SVR_KNN_stacking               | 0.6287             | 1.0476             | 0.2765             | 0.1744             | 0.4176             | 4.52               | 6.83               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_SVR_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_SVR_DecisionTree_stacking      | 0.5749             | 1.0544             | 0.2777             | 0.1996             | 0.4468             | 4.54               | 7.31               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_KNN_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_KNN_DecisionTree_stacking      | 0.5330             | 1.0598             | 0.2889             | 0.2193             | 0.4683             | 4.72               | 7.66               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: SVR_KNN_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| SVR_KNN_DecisionTree_stacking       | 0.6425             | 1.0458             | 0.2766             | 0.1679             | 0.4098             | 4.52               | 6.70               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_SVR_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_SVR_stacking | 0.6318             | 1.0472             | 0.2698             | 0.1729             | 0.4158             | 4.41               | 6.80               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_KNN_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_KNN_stacking | 0.5865             | 1.0530             | 0.2805             | 0.1942             | 0.4407             | 4.59               | 7.21               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_LGBM_DecisionTree_stacking\n",
      "+----------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                              | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+----------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_LGBM_DecisionTree_stacking | 0.5260             | 1.0607             | 0.2994             | 0.2226             | 0.4718             | 4.90               | 7.71               |\n",
      "+----------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_SVR_KNN_stacking\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                    | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_SVR_KNN_stacking | 0.6229             | 1.0483             | 0.2738             | 0.1771             | 0.4208             | 4.48               | 6.88               |\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_SVR_DecisionTree_stacking\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                             | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_SVR_DecisionTree_stacking | 0.5888             | 1.0527             | 0.2759             | 0.1931             | 0.4394             | 4.51               | 7.19               |\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_KNN_DecisionTree_stacking\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                             | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_KNN_DecisionTree_stacking | 0.5433             | 1.0585             | 0.2726             | 0.2145             | 0.4631             | 4.46               | 7.57               |\n",
      "+---------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_SVR_KNN_stacking    | 0.6537             | 1.0443             | 0.2646             | 0.1626             | 0.4032             | 4.33               | 6.59               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_SVR_DecisionTree_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_SVR_DecisionTree_stacking | 0.5822             | 1.0535             | 0.2672             | 0.1962             | 0.4429             | 4.37               | 7.24               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: ExtraTrees_LGBM_KNN_DecisionTree_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_LGBM_KNN_DecisionTree_stacking | 0.5475             | 1.0580             | 0.2849             | 0.2125             | 0.4610             | 4.66               | 7.54               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_SVR_KNN_DecisionTree_stacking\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                    | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_SVR_KNN_DecisionTree_stacking | 0.5727             | 1.0547             | 0.2976             | 0.2007             | 0.4480             | 4.87               | 7.33               |\n",
      "+------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_SVR_KNN_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_SVR_KNN_stacking  | 0.6103             | 1.0499             | 0.2814             | 0.1830             | 0.4278             | 4.60               | 6.99               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_SVR_DecisionTree_stacking\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                       | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_SVR_DecisionTree_stacking | 0.5659             | 1.0556             | 0.2854             | 0.2039             | 0.4515             | 4.67               | 7.38               |\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: RandomForest_LGBM_KNN_DecisionTree_stacking\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                       | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_LGBM_KNN_DecisionTree_stacking | 0.5408             | 1.0588             | 0.2842             | 0.2156             | 0.4644             | 4.65               | 7.59               |\n",
      "+---------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_SVR_KNN_DecisionTree_stacking\n",
      "+--------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                      | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+--------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_SVR_KNN_DecisionTree_stacking | 0.5664             | 1.0555             | 0.2875             | 0.2036             | 0.4512             | 4.70               | 7.38               |\n",
      "+--------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27378\n",
      "[LightGBM] [Info] Number of data points in the train set: 189, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.317510\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27541\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.327154\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27536\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.306804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27544\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.322698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27542\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.300231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27509\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 434\n",
      "[LightGBM] [Info] Start training from score 6.327884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27519\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.266593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27524\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 435\n",
      "[LightGBM] [Info] Start training from score 6.299884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27532\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 6.271545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27533\n",
      "[LightGBM] [Info] Number of data points in the train set: 190, number of used features: 436\n",
      "[LightGBM] [Info] Start training from score 6.308224\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30502\n",
      "[LightGBM] [Info] Number of data points in the train set: 211, number of used features: 438\n",
      "[LightGBM] [Info] Start training from score 6.304846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "训练 Stacking 模型: LGBM_SVR_KNN_DecisionTree_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| LGBM_SVR_KNN_DecisionTree_stacking  | 0.5415             | 1.0587             | 0.2990             | 0.2153             | 0.4640             | 4.89               | 7.59               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                                 模型名称  ...                                            n_model\n",
      "2                  ExtraTrees_SVR_stacking_stacking_3  ...                            ExtraTrees_SVR_stacking\n",
      "22            ExtraTrees_SVR_KNN_stacking_stacking_23  ...                        ExtraTrees_SVR_KNN_stacking\n",
      "12                       SVR_KNN_stacking_stacking_13  ...                                   SVR_KNN_stacking\n",
      "3                  ExtraTrees_KNN_stacking_stacking_4  ...                            ExtraTrees_KNN_stacking\n",
      "19           ExtraTrees_LGBM_SVR_stacking_stacking_20  ...                       ExtraTrees_LGBM_SVR_stacking\n",
      "41       ExtraTrees_LGBM_SVR_KNN_stacking_stacking_42  ...                   ExtraTrees_LGBM_SVR_KNN_stacking\n",
      "34          SVR_KNN_DecisionTree_stacking_stacking_35  ...                      SVR_KNN_DecisionTree_stacking\n",
      "23   ExtraTrees_SVR_DecisionTree_stacking_stacking_24  ...               ExtraTrees_SVR_DecisionTree_stacking\n",
      "35  ExtraTrees_RandomForest_LGBM_SVR_stacking_stac...  ...          ExtraTrees_RandomForest_LGBM_SVR_stacking\n",
      "16   ExtraTrees_RandomForest_SVR_stacking_stacking_17  ...               ExtraTrees_RandomForest_SVR_stacking\n",
      "31                  LGBM_SVR_KNN_stacking_stacking_32  ...                              LGBM_SVR_KNN_stacking\n",
      "9                       LGBM_SVR_stacking_stacking_10  ...                                  LGBM_SVR_stacking\n",
      "38  ExtraTrees_RandomForest_SVR_KNN_stacking_stack...  ...           ExtraTrees_RandomForest_SVR_KNN_stacking\n",
      "6                RandomForest_SVR_stacking_stacking_7  ...                          RandomForest_SVR_stacking\n",
      "25         RandomForest_LGBM_SVR_stacking_stacking_26  ...                     RandomForest_LGBM_SVR_stacking\n",
      "28          RandomForest_SVR_KNN_stacking_stacking_29  ...                      RandomForest_SVR_KNN_stacking\n",
      "45     RandomForest_LGBM_SVR_KNN_stacking_stacking_46  ...                 RandomForest_LGBM_SVR_KNN_stacking\n",
      "13              SVR_DecisionTree_stacking_stacking_14  ...                          SVR_DecisionTree_stacking\n",
      "24   ExtraTrees_KNN_DecisionTree_stacking_stacking_25  ...               ExtraTrees_KNN_DecisionTree_stacking\n",
      "17   ExtraTrees_RandomForest_KNN_stacking_stacking_18  ...               ExtraTrees_RandomForest_KNN_stacking\n",
      "20           ExtraTrees_LGBM_KNN_stacking_stacking_21  ...                       ExtraTrees_LGBM_KNN_stacking\n",
      "39  ExtraTrees_RandomForest_SVR_DecisionTree_stack...  ...  ExtraTrees_RandomForest_SVR_DecisionTree_stacking\n",
      "36  ExtraTrees_RandomForest_LGBM_KNN_stacking_stac...  ...          ExtraTrees_RandomForest_LGBM_KNN_stacking\n",
      "42  ExtraTrees_LGBM_SVR_DecisionTree_stacking_stac...  ...          ExtraTrees_LGBM_SVR_DecisionTree_stacking\n",
      "7                RandomForest_KNN_stacking_stacking_8  ...                          RandomForest_KNN_stacking\n",
      "0         ExtraTrees_RandomForest_stacking_stacking_1  ...                   ExtraTrees_RandomForest_stacking\n",
      "32         LGBM_SVR_DecisionTree_stacking_stacking_33  ...                     LGBM_SVR_DecisionTree_stacking\n",
      "29  RandomForest_SVR_DecisionTree_stacking_stackin...  ...             RandomForest_SVR_DecisionTree_stacking\n",
      "44  ExtraTrees_SVR_KNN_DecisionTree_stacking_stack...  ...           ExtraTrees_SVR_KNN_DecisionTree_stacking\n",
      "14              KNN_DecisionTree_stacking_stacking_15  ...                          KNN_DecisionTree_stacking\n",
      "48  RandomForest_SVR_KNN_DecisionTree_stacking_sta...  ...         RandomForest_SVR_KNN_DecisionTree_stacking\n",
      "46  RandomForest_LGBM_SVR_DecisionTree_stacking_st...  ...        RandomForest_LGBM_SVR_DecisionTree_stacking\n",
      "15  ExtraTrees_RandomForest_LGBM_stacking_stacking_16  ...              ExtraTrees_RandomForest_LGBM_stacking\n",
      "26         RandomForest_LGBM_KNN_stacking_stacking_27  ...                     RandomForest_LGBM_KNN_stacking\n",
      "43  ExtraTrees_LGBM_KNN_DecisionTree_stacking_stac...  ...          ExtraTrees_LGBM_KNN_DecisionTree_stacking\n",
      "18  ExtraTrees_RandomForest_DecisionTree_stacking_...  ...      ExtraTrees_RandomForest_DecisionTree_stacking\n",
      "40  ExtraTrees_RandomForest_KNN_DecisionTree_stack...  ...  ExtraTrees_RandomForest_KNN_DecisionTree_stacking\n",
      "30  RandomForest_KNN_DecisionTree_stacking_stackin...  ...             RandomForest_KNN_DecisionTree_stacking\n",
      "49     LGBM_SVR_KNN_DecisionTree_stacking_stacking_50  ...                 LGBM_SVR_KNN_DecisionTree_stacking\n",
      "47  RandomForest_LGBM_KNN_DecisionTree_stacking_st...  ...        RandomForest_LGBM_KNN_DecisionTree_stacking\n",
      "4         ExtraTrees_DecisionTree_stacking_stacking_5  ...                   ExtraTrees_DecisionTree_stacking\n",
      "33         LGBM_KNN_DecisionTree_stacking_stacking_34  ...                     LGBM_KNN_DecisionTree_stacking\n",
      "1                 ExtraTrees_LGBM_stacking_stacking_2  ...                           ExtraTrees_LGBM_stacking\n",
      "10                      LGBM_KNN_stacking_stacking_11  ...                                  LGBM_KNN_stacking\n",
      "37  ExtraTrees_RandomForest_LGBM_DecisionTree_stac...  ...  ExtraTrees_RandomForest_LGBM_DecisionTree_stac...\n",
      "21  ExtraTrees_LGBM_DecisionTree_stacking_stacking_22  ...              ExtraTrees_LGBM_DecisionTree_stacking\n",
      "8       RandomForest_DecisionTree_stacking_stacking_9  ...                 RandomForest_DecisionTree_stacking\n",
      "27  RandomForest_LGBM_DecisionTree_stacking_stacki...  ...            RandomForest_LGBM_DecisionTree_stacking\n",
      "5               RandomForest_LGBM_stacking_stacking_6  ...                         RandomForest_LGBM_stacking\n",
      "11             LGBM_DecisionTree_stacking_stacking_12  ...                         LGBM_DecisionTree_stacking\n",
      "\n",
      "[50 rows x 8 columns]\n",
      "完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_stacking.py \\\n",
    "    --data_path \"特征工程处理csv/坑塘水面_修正_处理后.csv\" \\\n",
    "    --model_save_path \"./model/农用地/Stacking模型/坑塘水面\" \\\n",
    "    --output_dir \"./模型评估/农用地/Stacking模型/坑塘水面\" \\\n",
    "    --comparison_save_path \"./模型评估/农用地/Stacking模型/坑塘水面Stacking模型对比.csv\" \\\n",
    "    --min_len 2 \\\n",
    "    --max_len 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 Stacking 模型: Ridge_BayesianRidge_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Ridge_BayesianRidge_stacking        | 0.5770             | 1.0204             | 0.3545             | 0.2164             | 0.4652             | 5.10               | 6.70               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_Ridge_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_Ridge_stacking         | 0.5611             | 1.0211             | 0.3666             | 0.2245             | 0.4738             | 5.28               | 6.82               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_Ridge_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_Ridge_stacking           | 0.5565             | 1.0214             | 0.3455             | 0.2268             | 0.4763             | 4.97               | 6.86               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_BayesianRidge_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_BayesianRidge_stacking | 0.5963             | 1.0194             | 0.3529             | 0.2065             | 0.4544             | 5.08               | 6.54               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_BayesianRidge_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_BayesianRidge_stacking   | 0.5970             | 1.0194             | 0.3447             | 0.2061             | 0.4540             | 4.96               | 6.53               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_stacking\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                               | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_stacking    | 0.5652             | 1.0209             | 0.3814             | 0.2224             | 0.4716             | 5.49               | 6.79               |\n",
      "+-------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: RandomForest_Ridge_BayesianRidge_stacking\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                     | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| RandomForest_Ridge_BayesianRidge_stacking | 0.5961             | 1.0195             | 0.3551             | 0.2066             | 0.4545             | 5.11               | 6.54               |\n",
      "+-------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_Ridge_BayesianRidge_stacking\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                   | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_Ridge_BayesianRidge_stacking | 0.5937             | 1.0196             | 0.3513             | 0.2078             | 0.4559             | 5.06               | 6.56               |\n",
      "+-----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_Ridge_stacking\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                  | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_Ridge_stacking | 0.5760             | 1.0204             | 0.3610             | 0.2169             | 0.4657             | 5.20               | 6.70               |\n",
      "+----------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "训练 Stacking 模型: ExtraTrees_RandomForest_BayesianRidge_stacking\n",
      "+------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Model                                          | R^2                | Adj R^2            | MAE                | MSE                | RMSE               | %MAE               | %RMSE              |\n",
      "+------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ExtraTrees_RandomForest_BayesianRidge_stacking | 0.5954             | 1.0195             | 0.3531             | 0.2069             | 0.4549             | 5.08               | 6.55               |\n",
      "+------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "                                                模型名称  ...                                         n_model\n",
      "4       ExtraTrees_BayesianRidge_stacking_stacking_5  ...               ExtraTrees_BayesianRidge_stacking\n",
      "3     RandomForest_BayesianRidge_stacking_stacking_4  ...             RandomForest_BayesianRidge_stacking\n",
      "6  RandomForest_Ridge_BayesianRidge_stacking_stac...  ...       RandomForest_Ridge_BayesianRidge_stacking\n",
      "9  ExtraTrees_RandomForest_BayesianRidge_stacking...  ...  ExtraTrees_RandomForest_BayesianRidge_stacking\n",
      "7  ExtraTrees_Ridge_BayesianRidge_stacking_stacki...  ...         ExtraTrees_Ridge_BayesianRidge_stacking\n",
      "0            Ridge_BayesianRidge_stacking_stacking_1  ...                    Ridge_BayesianRidge_stacking\n",
      "8  ExtraTrees_RandomForest_Ridge_stacking_stacking_9  ...          ExtraTrees_RandomForest_Ridge_stacking\n",
      "5        ExtraTrees_RandomForest_stacking_stacking_6  ...                ExtraTrees_RandomForest_stacking\n",
      "1             RandomForest_Ridge_stacking_stacking_2  ...                     RandomForest_Ridge_stacking\n",
      "2               ExtraTrees_Ridge_stacking_stacking_3  ...                       ExtraTrees_Ridge_stacking\n",
      "\n",
      "[10 rows x 8 columns]\n",
      "完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BayesianRidge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_stacking.py \\\n",
    "    --data_path \"特征工程处理csv/设施农用地_修正_处理后.csv\" \\\n",
    "    --model_save_path \"./model/农用地/Stacking模型/设施农用地\" \\\n",
    "    --output_dir \"./模型评估/农用地/Stacking模型/设施农用地\" \\\n",
    "    --comparison_save_path \"./模型评估/农用地/Stacking模型/设施农用地Stacking模型对比.csv\" \\\n",
    "    --min_len 2 \\\n",
    "    --max_len 3 \\\n",
    "    --selected_models  Ridge BayesianRidge RandomForest ExtraTrees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 公服用地-stacking"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练Stacking模型 1/11: ExtraTreesRegressor_RandomForestRegressor_stacking\n",
      "评估模型: ExtraTreesRegressor_RandomForestRegressor_stacking\n",
      "R^2: 0.8039188085875881\n",
      "Adjusted R^2: 1.0343390918970976\n",
      "MAE: 291.5658753272221\n",
      "MSE: 212554.436855326\n",
      "RMSE: 461.03626414342506\n",
      "%MAE: 18.151718952414686\n",
      "%RMSE: 28.702263885342056\n",
      "训练Stacking模型 2/11: ExtraTreesRegressor_LGBMRegressor_stacking\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37353\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1545.257937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37389\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1582.468254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37370\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1513.992063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37397\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.845238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37366\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1541.432540\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37378\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1563.396825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37391\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1575.773810\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37386\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.428571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37360\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1576.920635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37387\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score 1551.162698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41197\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1557.567857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "评估模型: ExtraTreesRegressor_LGBMRegressor_stacking\n",
      "R^2: 0.8147733358213929\n",
      "Adjusted R^2: 1.0324381721531064\n",
      "MAE: 282.4567778627258\n",
      "MSE: 200787.9950722405\n",
      "RMSE: 448.0937346942496\n",
      "%MAE: 17.58462317380162\n",
      "%RMSE: 27.896514046369564\n",
      "训练Stacking模型 3/11: ExtraTreesRegressor_SGDRegressor_stacking\n",
      "评估模型: ExtraTreesRegressor_SGDRegressor_stacking\n",
      "R^2: 0.7954880281400561\n",
      "Adjusted R^2: 1.0358155483714115\n",
      "MAE: 326.34650064338496\n",
      "MSE: 221693.50714232246\n",
      "RMSE: 470.84339980753947\n",
      "%MAE: 20.31702082465777\n",
      "%RMSE: 29.312816715310312\n",
      "训练Stacking模型 4/11: RandomForestRegressor_LGBMRegressor_stacking\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37353\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1545.257937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37389\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1582.468254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37370\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1513.992063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37397\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.845238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37366\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1541.432540\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37378\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1563.396825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37391\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1575.773810\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37386\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.428571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37360\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1576.920635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37387\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score 1551.162698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41197\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1557.567857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "评估模型: RandomForestRegressor_LGBMRegressor_stacking\n",
      "R^2: 0.7830614360644053\n",
      "Adjusted R^2: 1.0379917789633402\n",
      "MAE: 313.29270152521616\n",
      "MSE: 235164.08665912785\n",
      "RMSE: 484.93719867538294\n",
      "%MAE: 19.504343783531635\n",
      "%RMSE: 30.19023995880149\n",
      "训练Stacking模型 5/11: RandomForestRegressor_SGDRegressor_stacking\n",
      "评估模型: RandomForestRegressor_SGDRegressor_stacking\n",
      "R^2: 0.766417335077786\n",
      "Adjusted R^2: 1.0409066088315553\n",
      "MAE: 340.5386804094563\n",
      "MSE: 253206.49800256538\n",
      "RMSE: 503.1962817853142\n",
      "%MAE: 21.200568867263087\n",
      "%RMSE: 31.326977049753197\n",
      "训练Stacking模型 6/11: LGBMRegressor_SGDRegressor_stacking\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37353\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1545.257937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37389\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1582.468254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37370\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1513.992063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37397\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.845238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37366\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1541.432540\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37378\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1563.396825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37391\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1575.773810\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37386\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.428571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37360\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1576.920635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37387\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score 1551.162698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41197\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1557.567857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "评估模型: LGBMRegressor_SGDRegressor_stacking\n",
      "R^2: 0.777340908484026\n",
      "Adjusted R^2: 1.0389935972451834\n",
      "MAE: 356.37007882306995\n",
      "MSE: 241365.2093145153\n",
      "RMSE: 491.28933360547865\n",
      "%MAE: 22.18616807123409\n",
      "%RMSE: 30.585698336327706\n",
      "训练Stacking模型 7/11: ExtraTreesRegressor_RandomForestRegressor_LGBMRegressor_stacking\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37353\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1545.257937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37389\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1582.468254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37370\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1513.992063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37397\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.845238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37366\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1541.432540\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37378\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1563.396825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37391\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1575.773810\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37386\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.428571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37360\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1576.920635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37387\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score 1551.162698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41197\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1557.567857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "评估模型: ExtraTreesRegressor_RandomForestRegressor_LGBMRegressor_stacking\n",
      "R^2: 0.8034227546320702\n",
      "Adjusted R^2: 1.0344259642903226\n",
      "MAE: 291.56520747979425\n",
      "MSE: 213092.16547888974\n",
      "RMSE: 461.619069665552\n",
      "%MAE: 18.151677374919377\n",
      "%RMSE: 28.738547013570592\n",
      "训练Stacking模型 8/11: ExtraTreesRegressor_RandomForestRegressor_SGDRegressor_stacking\n",
      "评估模型: ExtraTreesRegressor_RandomForestRegressor_SGDRegressor_stacking\n",
      "R^2: 0.7920166202890134\n",
      "Adjusted R^2: 1.0364234852793353\n",
      "MAE: 325.2172144843695\n",
      "MSE: 225456.5561913341\n",
      "RMSE: 474.82265762212114\n",
      "%MAE: 20.24671600948591\n",
      "%RMSE: 29.560549305444265\n",
      "训练Stacking模型 9/11: ExtraTreesRegressor_LGBMRegressor_SGDRegressor_stacking\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37353\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1545.257937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37389\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1582.468254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37370\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1513.992063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37397\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.845238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37366\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1541.432540\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37378\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1563.396825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37391\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1575.773810\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37386\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.428571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37360\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1576.920635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37387\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score 1551.162698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41197\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1557.567857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "评估模型: ExtraTreesRegressor_LGBMRegressor_SGDRegressor_stacking\n",
      "R^2: 0.7990314312807012\n",
      "Adjusted R^2: 1.0351950031513493\n",
      "MAE: 322.7183604514091\n",
      "MSE: 217852.4143088589\n",
      "RMSE: 466.7466275281043\n",
      "%MAE: 20.091147405792153\n",
      "%RMSE: 29.057768147144053\n",
      "训练Stacking模型 10/11: RandomForestRegressor_LGBMRegressor_SGDRegressor_stacking\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37353\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1545.257937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37389\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1582.468254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37370\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1513.992063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37397\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.845238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37366\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1541.432540\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37378\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1563.396825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37391\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1575.773810\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37386\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.428571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37360\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1576.920635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37387\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score 1551.162698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41197\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1557.567857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "评估模型: RandomForestRegressor_LGBMRegressor_SGDRegressor_stacking\n",
      "R^2: 0.7745978404159739\n",
      "Adjusted R^2: 1.0394739822621772\n",
      "MAE: 339.23946426928865\n",
      "MSE: 244338.72902979655\n",
      "RMSE: 494.30631093462335\n",
      "%MAE: 21.11968489478758\n",
      "%RMSE: 30.77352321296315\n",
      "训练Stacking模型 11/11: ExtraTreesRegressor_RandomForestRegressor_LGBMRegressor_SGDRegressor_stacking\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37353\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1545.257937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37389\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1582.468254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37370\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1513.992063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37397\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.845238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37366\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1541.432540\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37378\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1563.396825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37391\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1575.773810\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37386\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 448\n",
      "[LightGBM] [Info] Start training from score 1562.428571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37360\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1576.920635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37387\n",
      "[LightGBM] [Info] Number of data points in the train set: 252, number of used features: 447\n",
      "[LightGBM] [Info] Start training from score 1551.162698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41197\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 449\n",
      "[LightGBM] [Info] Start training from score 1557.567857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "评估模型: ExtraTreesRegressor_RandomForestRegressor_LGBMRegressor_SGDRegressor_stacking\n",
      "R^2: 0.7913222472368463\n",
      "Adjusted R^2: 1.0365450886818721\n",
      "MAE: 325.21766348192574\n",
      "MSE: 226209.26516871108\n",
      "RMSE: 475.6146183294949\n",
      "%MAE: 20.246743962268255\n",
      "%RMSE: 29.609853594450897\n",
      "                                                 模型名称  ...                                            n_model\n",
      "1   ExtraTreesRegressor_LGBMRegressor_stacking_sta...  ...         ExtraTreesRegressor_LGBMRegressor_stacking\n",
      "0   ExtraTreesRegressor_RandomForestRegressor_stac...  ...  ExtraTreesRegressor_RandomForestRegressor_stac...\n",
      "6   ExtraTreesRegressor_RandomForestRegressor_LGBM...  ...  ExtraTreesRegressor_RandomForestRegressor_LGBM...\n",
      "8   ExtraTreesRegressor_LGBMRegressor_SGDRegressor...  ...  ExtraTreesRegressor_LGBMRegressor_SGDRegressor...\n",
      "2   ExtraTreesRegressor_SGDRegressor_stacking_stac...  ...          ExtraTreesRegressor_SGDRegressor_stacking\n",
      "7   ExtraTreesRegressor_RandomForestRegressor_SGDR...  ...  ExtraTreesRegressor_RandomForestRegressor_SGDR...\n",
      "10  ExtraTreesRegressor_RandomForestRegressor_LGBM...  ...  ExtraTreesRegressor_RandomForestRegressor_LGBM...\n",
      "3   RandomForestRegressor_LGBMRegressor_stacking_s...  ...       RandomForestRegressor_LGBMRegressor_stacking\n",
      "5      LGBMRegressor_SGDRegressor_stacking_stacking_6  ...                LGBMRegressor_SGDRegressor_stacking\n",
      "9   RandomForestRegressor_LGBMRegressor_SGDRegress...  ...  RandomForestRegressor_LGBMRegressor_SGDRegress...\n",
      "4   RandomForestRegressor_SGDRegressor_stacking_st...  ...        RandomForestRegressor_SGDRegressor_stacking\n",
      "\n",
      "[11 rows x 8 columns]\n",
      "完成操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but ExtraTreesRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\arcgispro-py3\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/model_training_stacking.py \\\n",
    "    --data_path \"特征工程处理csv/公服用地_修正_处理后.csv\" \\\n",
    "    --model_save_path \"./model/建设用地/Stacking模型/公服用地\" \\\n",
    "    --output_dir \"./模型评估/建设用地/Stacking模型/公服用地\" \\\n",
    "    --comparison_save_path \"./模型评估/建设用地/Stacking模型/公服用地Stacking模型对比.csv\" \\\n",
    "    --min_len 2 \\\n",
    "    --max_len 5 \\\n",
    "    # --selected_models ExtraTrees RandomForest LGBM SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import metrics\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 初始化评估指标列表\n",
    "models_name = []\n",
    "RR = []\n",
    "MAE = []\n",
    "MSE = []\n",
    "RMSE = []\n",
    "MAE_B = []\n",
    "RMSE_B = []\n",
    "n_model = []\n",
    "\n",
    "# 加载数据集\n",
    "train = pd.read_csv('./建设用地/商业处理后数据.csv', encoding='gbk')\n",
    "\n",
    "# 备份数据\n",
    "data = train.copy()\n",
    "X = train.drop(['YDDJ'], axis=1)\n",
    "y = train['YDDJ']\n",
    "\n",
    "# 数据标准化\n",
    "for column in X.columns:\n",
    "    mean = X[column].mean()\n",
    "    std = X[column].std()\n",
    "    X[column] = (X[column] - mean) / std\n",
    "\n",
    "X.set_index(data['OBJECTID'], inplace=True)\n",
    "y.index = data['OBJECTID']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "\n",
    "# 定义元回归模型\n",
    "meta_regressor = LinearRegression()\n",
    "\n",
    "# 定义基础回归模型\n",
    "base_models = [\n",
    "    ExtraTreesRegressor(n_estimators=100, random_state=45),\n",
    "    RandomForestRegressor(n_estimators=200, random_state=45),\n",
    "    lgb.LGBMRegressor(n_estimators=200, random_state=45),\n",
    "    SVR(),\n",
    "    KNeighborsRegressor(),\n",
    "    DecisionTreeRegressor()\n",
    "]\n",
    "\n",
    "# 生成基础模型组合\n",
    "from itertools import combinations\n",
    "\n",
    "def generate_combinations(models, min_len=2, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = len(models)\n",
    "    return [list(combo) for i in range(min_len, max_len + 1) for combo in combinations(models, i)]\n",
    "\n",
    "model_combinations = generate_combinations(base_models, min_len=2, max_len=4)\n",
    "\n",
    "def get_model_name(models):\n",
    "    \"\"\"生成模型名称\"\"\"\n",
    "    model_names = []\n",
    "    if any(isinstance(m, ExtraTreesRegressor) for m in models):\n",
    "        model_names.append('ExtraTrees')\n",
    "    if any(isinstance(m, RandomForestRegressor) for m in models):\n",
    "        model_names.append('RandomForest')\n",
    "    if any(isinstance(m, lgb.LGBMRegressor) for m in models):\n",
    "        model_names.append('LGBM')\n",
    "    if any(isinstance(m, SVR) for m in models):\n",
    "        model_names.append('SVR')\n",
    "    if any(isinstance(m, KNeighborsRegressor) for m in models):\n",
    "        model_names.append('KNN')\n",
    "    if any(isinstance(m, DecisionTreeRegressor) for m in models):\n",
    "        model_names.append('DecisionTree')\n",
    "    return '_'.join(model_names) + '_stacking'\n",
    "\n",
    "# 创建堆叠回归模型\n",
    "cv = KFold(n_splits=10)\n",
    "n_jobs = 1\n",
    "\n",
    "for i, models in enumerate(model_combinations, start=1):\n",
    "    # 创建和训练堆叠回归模型\n",
    "    stacking_reg = StackingCVRegressor(regressors=models, meta_regressor=meta_regressor, cv=cv, verbose=0, random_state=45, n_jobs=n_jobs)\n",
    "    stacking_reg.fit(X_train, y_train)\n",
    "\n",
    "    # 生成模型名称\n",
    "    model_name = get_model_name(models)\n",
    "\n",
    "    # 评估模型\n",
    "    def T_stacking(reg, n, model_name):\n",
    "        y_pred = reg.predict(X_train)\n",
    "        y_test_pred = reg.predict(X_test)\n",
    "\n",
    "        res = pd.DataFrame()\n",
    "        res['OBJECTID'] = list(X_test.index)\n",
    "        res['真实值'] = list(y_test)\n",
    "        res['预测值'] = y_test_pred\n",
    "        y_test.index = list(range(len(y_test.index)))\n",
    "        loss = [abs(y_test[i] - y_test_pred[i]) for i in range(len(y_test))]\n",
    "        res['差值'] = loss\n",
    "\n",
    "        point = data.loc[:, ['OBJECTID']]\n",
    "        res = pd.merge(res, point)\n",
    "        res.set_index(['OBJECTID'])\n",
    "        res.to_csv(f'./模型评估/建设用地/Stacking集成模型/商业/{model_name}_stacking_{n}.csv', index=False, float_format='%.2f', encoding='gbk')\n",
    "\n",
    "        acc_rf = metrics.r2_score(y_test, y_test_pred)\n",
    "        adjr2_rf = 1 - (1 - metrics.r2_score(y_test, y_test_pred)) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "        MAE_rf = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "        MSE_rf = metrics.mean_squared_error(y_test, y_test_pred)\n",
    "        RMSE_rf = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "        MAE_b = (MAE_rf / np.mean(np.abs(y_test))) * 100\n",
    "        RMSE_b = (RMSE_rf / np.mean(np.abs(y_test))) * 100\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(f'Model {model_name} ({n})')\n",
    "        print('R^2:', acc_rf)\n",
    "        print('Adjusted R^2:', adjr2_rf)\n",
    "        print('MAE:', MAE_rf)\n",
    "        print('MSE:', MSE_rf)\n",
    "        print('RMSE:', RMSE_rf)\n",
    "        print('%MAE:', MAE_b)\n",
    "        print('%RMSE:', RMSE_b)\n",
    "        print(\"------------------------------------------------\")\n",
    "\n",
    "        models_name.append(f'{model_name}_stacking_{n}')\n",
    "        RR.append(acc_rf)\n",
    "        MAE.append(MAE_rf)\n",
    "        MSE.append(MSE_rf)\n",
    "        RMSE.append(RMSE_rf)\n",
    "        MAE_B.append(MAE_b)\n",
    "        RMSE_B.append(RMSE_b)\n",
    "        n_model.append(models)\n",
    "        \n",
    "        # 保存模型\n",
    "        model_path = f'./model/建设用地/Stacking集成模型/商业/'\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        joblib.dump(reg, f'{model_path}/{model_name}_stacking_{n}.pkl')\n",
    "\n",
    "    # 调用评估函数\n",
    "    T_stacking(stacking_reg, i, model_name)\n",
    "\n",
    "# 创建 DataFrame 保存评估结果\n",
    "df = pd.DataFrame({'模型名称': models_name, 'R^2': RR, 'MAE': MAE, 'MSE': MSE, 'RMSE': RMSE, '%MAE': MAE_B, '%RMSE': RMSE_B, 'n_model': n_model})\n",
    "\n",
    "# 根据 R^2 对模型进行排序\n",
    "df = df.sort_values(by='R^2', ascending=False)\n",
    "\n",
    "print(df)\n",
    "df.to_csv('./模型对比csv文件夹/建设用地/Stacking集成模型/商业stacking模型对比.csv', index=True, float_format='%.6f', encoding='gbk')\n",
    "print('完成操作')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
